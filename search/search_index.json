{
    "docs": [
        {
            "location": "/", 
            "text": "HSR Notizen\n\n\nSpring Semester 2018\n\n\n\n\nCloud Solutions\n\n\nCompilerbau\n\n\nDeep Learning\n\n\n\n\nLinks\n\n\n\n\nMathJax Syntax\n\n\nMkDocs User-Guide\n\n\nMarkdown Cheatsheet", 
            "title": "Home"
        }, 
        {
            "location": "/#hsr-notizen", 
            "text": "", 
            "title": "HSR Notizen"
        }, 
        {
            "location": "/#spring-semester-2018", 
            "text": "Cloud Solutions  Compilerbau  Deep Learning", 
            "title": "Spring Semester 2018"
        }, 
        {
            "location": "/#links", 
            "text": "MathJax Syntax  MkDocs User-Guide  Markdown Cheatsheet", 
            "title": "Links"
        }, 
        {
            "location": "/playground/", 
            "text": "Markdown Playground\n\n\nDies ist etwas normaler Text mit etwas \nkursiver\n schrift und etwas \nbold\n schrift\n\n\nDieser Text ist \nmarkiert\n, hier sind emojis: \n \n \n\n\n\n\n1\n2\nDies ist Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text\nzweite Zeile\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n  \npublic\n \nclass\n \nTestClass\n()\n \n{\n\n    \nint\n \nvar\n \n=\n \n1\n;\n\n\n    \npublic\n \nmethod\n()\n \n{\n\n\n      \nreturn\n \nvar\n;\n\n\n    \n}\n\n\n  \n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\n\n\n\n\n\n\n\n1\n\n\netwas\n\n\nanderes\n\n\n\n\n\n\n2\n\n\nals\n\n\nhier\n\n\n\n\n\n\n\n\n\n\nNotiz\n\n\nTest Notiz mit etwas Text drin\n\n\n\n\nNote\nKlapp mich auf!\n\n\nDanger\n\n\nGefahr!\n\n\n\n\n\n\nWarning\n\n\nWarnung!\n\n\n\n\n\n\nSummary\n\n\nEine Zusammenfassung\n\n\n\n\n\n\nInfo\n\n\nEine Information\n\n\n\n\n\n\nTip\n\n\nEin Tip\n\n\n\n\n\n\nQuestion\n\n\nEine Frage\n\n\n\n\n\n\nBug\n\n\nEin Bug\n\n\n\n\n\n\nQuote\n\n\nEin Zitat\n\n\n\n\nInline Math: \n x_i^2 * \\frac{(n^2 * n) - 1}{\\Omega} \n\n\n\n\nDisplay Math:\n\n\\sum_{i=0}^n i^2\n\n\n\n\nGruppen mit \n{}\n: \n{10}^5\n\n\n\n\n\n\nA \\rightarrow B \n\n\n\\lim_{x\\to \\infty} \\sin x", 
            "title": "Playground"
        }, 
        {
            "location": "/playground/#markdown-playground", 
            "text": "Dies ist etwas normaler Text mit etwas  kursiver  schrift und etwas  bold  schrift  Dieser Text ist  markiert , hier sind emojis:        1\n2 Dies ist Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text ein Text\nzweite Zeile   1\n2\n3\n4\n5\n6    public   class   TestClass ()   { \n     int   var   =   1 ;       public   method ()   {         return   var ;       }     }       1  2  3      1  etwas  anderes    2  als  hier      Notiz  Test Notiz mit etwas Text drin   Note Klapp mich auf!  Danger  Gefahr!    Warning  Warnung!    Summary  Eine Zusammenfassung    Info  Eine Information    Tip  Ein Tip    Question  Eine Frage    Bug  Ein Bug    Quote  Ein Zitat   Inline Math:   x_i^2 * \\frac{(n^2 * n) - 1}{\\Omega}    Display Math: \\sum_{i=0}^n i^2   Gruppen mit  {} :  {10}^5    A \\rightarrow B   \\lim_{x\\to \\infty} \\sin x", 
            "title": "Markdown Playground"
        }, 
        {
            "location": "/clou/", 
            "text": "Cloud Solutions", 
            "title": "Index"
        }, 
        {
            "location": "/clou/#cloud-solutions", 
            "text": "", 
            "title": "Cloud Solutions"
        }, 
        {
            "location": "/clou/introduction/", 
            "text": "Introduction\n\n\nAnforderung an Cloud Provider\n\n\n\n\nAvailability\n\n\nOn Boarding (einfach zu bedienen)\n\n\nVerschiedene Interfaces (z.B. API, Browser)\n\n\nOn Demand: Nicht auf Installation warten m\u00fcssen\n\n\nSecurity-Zusicherungen\n\n\nScalability\n\n\nTooling (z.B. Monitoring)\n\n\nModular\n\n\nKein Vendor lock-in\n\n\n\n\nMeasurable: z.B. transparente Kosten\n\n\n\n\n\n\nNIST-Standard ist weniger spezifisch als \"OSSM\"\n\n\n\n\nz.B. nichts \u00fcber Monitoring, API-Access, ...", 
            "title": "Introduction"
        }, 
        {
            "location": "/clou/introduction/#introduction", 
            "text": "", 
            "title": "Introduction"
        }, 
        {
            "location": "/clou/introduction/#anforderung-an-cloud-provider", 
            "text": "Availability  On Boarding (einfach zu bedienen)  Verschiedene Interfaces (z.B. API, Browser)  On Demand: Nicht auf Installation warten m\u00fcssen  Security-Zusicherungen  Scalability  Tooling (z.B. Monitoring)  Modular  Kein Vendor lock-in   Measurable: z.B. transparente Kosten    NIST-Standard ist weniger spezifisch als \"OSSM\"   z.B. nichts \u00fcber Monitoring, API-Access, ...", 
            "title": "Anforderung an Cloud Provider"
        }, 
        {
            "location": "/clou/sla_eval/", 
            "text": "Patterns, SLA, Evaluation\n\n\nSLAs\n\n\n\n\nAmazon bietet 99.99% Verf\u00fcgbarkeit in ihrer SLA\n\n\nEin SLA definiert messbar die Offerings des Providers, und welche Konsequenzen bei Verletzen entstehen\n\n\nDiese Ziele (aus NFA) sind Service Level Objectives (SLO)\n\n\n\n\n\n\nCustomer Agreement: Vertragsbedingungen, z.B. K\u00fcndigungsfrist\n\n\nAcceptable Use Policies (AUPs): F\u00fcr was darf der Service verwendet werden (z.B. keine Malware hosten)\n\n\nEin SLO besteht aus dem Service, das Quality-Attribut und ein Threshold-Value\n\n\nEs wird auch festgehalten, zu wie viel Prozent ein SLo eingehalten werden muss\n\n\nbsp. : SLO ist \"Response time under 1 second\", dies muss zu 90% eingehalten werden\n\n\n\n\n\n\n\n\nCC Patterns\n\n\nEvaluationstechniken und -kriterien", 
            "title": "SLAs/Patterns"
        }, 
        {
            "location": "/clou/sla_eval/#patterns-sla-evaluation", 
            "text": "", 
            "title": "Patterns, SLA, Evaluation"
        }, 
        {
            "location": "/clou/sla_eval/#slas", 
            "text": "Amazon bietet 99.99% Verf\u00fcgbarkeit in ihrer SLA  Ein SLA definiert messbar die Offerings des Providers, und welche Konsequenzen bei Verletzen entstehen  Diese Ziele (aus NFA) sind Service Level Objectives (SLO)    Customer Agreement: Vertragsbedingungen, z.B. K\u00fcndigungsfrist  Acceptable Use Policies (AUPs): F\u00fcr was darf der Service verwendet werden (z.B. keine Malware hosten)  Ein SLO besteht aus dem Service, das Quality-Attribut und ein Threshold-Value  Es wird auch festgehalten, zu wie viel Prozent ein SLo eingehalten werden muss  bsp. : SLO ist \"Response time under 1 second\", dies muss zu 90% eingehalten werden", 
            "title": "SLAs"
        }, 
        {
            "location": "/clou/sla_eval/#cc-patterns", 
            "text": "", 
            "title": "CC Patterns"
        }, 
        {
            "location": "/clou/sla_eval/#evaluationstechniken-und-kriterien", 
            "text": "", 
            "title": "Evaluationstechniken und -kriterien"
        }, 
        {
            "location": "/combau/", 
            "text": "Compilerbau", 
            "title": "Index"
        }, 
        {
            "location": "/combau/#compilerbau", 
            "text": "", 
            "title": "Compilerbau"
        }, 
        {
            "location": "/combau/syntax/", 
            "text": "Syntax\n\n\nRappi# Syntax\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\nrappi_sharp \n=\n \n{\nclass_declaration\n}.\n\n\n\nclass_declaration \n=\n \n    \nclass\n \nclass_identifier \n[\n:\n \nclass_identifier\n]\n \n{\n \n{\nfield_declaration\n}\n \n}\n.\n\n\n\n//\n \nnot specified exactly\n,\n \nare numbers allowed\n?\n\n\nclass_identifier \n=\n \nuppercase_letter \n{\nletter\n}.\n\n\n\nuppercase_letter \n=\n \nA\n \n|\n \n.\n.\n \n|\n \nZ\n.\n\n\n\nlowercase_letter \n=\n \na\n \n|\n \n.\n.\n \n|\n \nz\n.\n\n\n\nletter \n=\n \nuppercase_letter \n|\n \nlowercase_letter\n.\n\n\n\nfield_declaration \n=\n \nvariable_declaration \n|\n \nmethod_declaration\n.\n\n\n\nvariable_declaration \n=\n \ntype variable_identifier \n;\n.\n\n\n\ntype \n=\n \n//\n \nTODO\n:\n \ncan be user defined or default type\n\n\n\n//\n \nnot specified exactly\n\n\nvariable_identifier \n=\n \nlowercase_letter \n{\nletter\n}.\n\n\n\nmethod_declaration \n=\n \n    \ntype method_identifier \n(\n \n[\nparameter_list\n]\n \n)\n \n{\n \n{\nstatement\n}\n \n}\n.\n\n\n\n//\n \nTODO separate to class identifier\n?\n\n\nmethod_identifer \n=\n \nclass_identifier\n.\n\n\n\nparameter_list \n=\n \nparameter \n{\n,\n \nparameter\n}.\n\n\n\nparameter \n=\n \ntype variable_identifier\n.\n\n\n\nstatement \n=\n \n      \n;\n\n    \n|\n \nvariable_declaration\n\n    \n|\n \nvariable_assignment\n\n    \n|\n \nif_statement\n\n    \n|\n \nwhile_statement\n\n    \n|\n \nmethod_call\n\n    \n|\n \nreturn_statement\n.\n\n\n\nvariable_assignment \n=\n \nvariable_identifier \n=\n \nexpression \n;\n.\n\n\n\nif_statement \n=\n \n    \nif\n \n(\n \nexpression \n)\n \n{\n \n{\nstatement\n}\n \n}\n \n{\nelse\n \n{\n \n{\nstatement\n}\n \n}\n}.\n\n\n\nwhile_statement \n=\n \n    \nwhile\n \n(\n \nexpression \n)\n \n{\n \n{\nstatement\n}\n \n}\n.\n\n\n\nmethod_call \n=\n \n    \n[\ndesignator \n.\n]\n \nmethod_identifier \n(\n \n[\nargument_list\n]\n \n)\n \n;\n.\n\n\n\nreturn_statement \n=\n \nreturn\n \n[\nexpression\n]\n \n;\n.\n\n\n\nargument_list \n=\n \nexpression \n{\n,\n \nexpression\n}.\n\n\n\nexpression \n=\n\n      \nconstant_value\n\n    \n|\n \ncomparison_expression\n\n    \n|\n \nlogical_expression\n\n\n\n//\n \nTODO\n:\n \nExtend expression definition", 
            "title": "Syntax"
        }, 
        {
            "location": "/combau/syntax/#syntax", 
            "text": "", 
            "title": "Syntax"
        }, 
        {
            "location": "/combau/syntax/#rappi-syntax", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63 rappi_sharp  =   { class_declaration }.  class_declaration  =  \n     class   class_identifier  [ :   class_identifier ]   {   { field_declaration }   } .  //   not specified exactly ,   are numbers allowed ?  class_identifier  =   uppercase_letter  { letter }.  uppercase_letter  =   A   |   . .   |   Z .  lowercase_letter  =   a   |   . .   |   z .  letter  =   uppercase_letter  |   lowercase_letter .  field_declaration  =   variable_declaration  |   method_declaration .  variable_declaration  =   type variable_identifier  ; .  type  =   //   TODO :   can be user defined or default type  //   not specified exactly  variable_identifier  =   lowercase_letter  { letter }.  method_declaration  =  \n     type method_identifier  (   [ parameter_list ]   )   {   { statement }   } .  //   TODO separate to class identifier ?  method_identifer  =   class_identifier .  parameter_list  =   parameter  { ,   parameter }.  parameter  =   type variable_identifier .  statement  =  \n       ; \n     |   variable_declaration \n     |   variable_assignment \n     |   if_statement \n     |   while_statement \n     |   method_call \n     |   return_statement .  variable_assignment  =   variable_identifier  =   expression  ; .  if_statement  =  \n     if   (   expression  )   {   { statement }   }   { else   {   { statement }   } }.  while_statement  =  \n     while   (   expression  )   {   { statement }   } .  method_call  =  \n     [ designator  . ]   method_identifier  (   [ argument_list ]   )   ; .  return_statement  =   return   [ expression ]   ; .  argument_list  =   expression  { ,   expression }.  expression  = \n       constant_value \n     |   comparison_expression \n     |   logical_expression  //   TODO :   Extend expression definition", 
            "title": "Rappi# Syntax"
        }, 
        {
            "location": "/combau/lexer/", 
            "text": "Lexer\n\n\nTrailing else problem\n\n\n\n\nNicht eindeutige Syntax\n\n\nJava umgeht das mit separat definiertem \"StatementNoShortIf\"\n\n\n\n\nLexikalische Analyse\n\n\n\n\nAnalyse von Terminalsymbolen zu Tokens\n\n\nToken = \"Terminalsymbol\"\n\n\n\n\n\n\nVon Charakter-Stream zu Token-Stream\n\n\nFasst mehrere Textzeichen zusammen zu Tokens\n\n\nEliminiert Whitespaces und Code-Kommentare\n\n\nWhitespace ist aber relevant, um Tokens zu trennen\n\n\nKommentare k\u00f6nnen z.B. f\u00fcr Refactoring-Tools relevant sein\n\n\n\n\n\n\nMerkt Position von Tokens im Code f\u00fcr Fehlermeldung und Debugging\n\n\n\n\nNutzer f\u00fcr Parser\n\n\n\n\nParser arbeitet nur mit Tokens\n\n\nLookahead pro Symbol (nur n\u00e4chstes Symbol)\n\n\n\n\nTokens\n\n\n\n\nKeywords sind reservierte Begriffe\n\n\nInterpunktionen wie \n;\n, \n{\n, \n]\n etc.\n\n\nIdentifiers sind \"custom\" tokens wie Variablennamen (die keine keywords sein d\u00fcrfen)\n\n\nReservierte typennamen und Werte (true, false, ...) nicht als fixe Tokens scannen, sondern als Identifier\n\n\n\n\nRegul\u00e4re Sprachen\n\n\n\n\nScanner / Lexer versteht nur regul\u00e4re Sprachen\n\n\nin EBNF ohne Rekursion m\u00f6glich = regul\u00e4r\n\n\n= als eine EBNF-Regel formulierbar\n\n\n\n\n\n\n\u00ccnteger = Digit [ Integer ]\n ist rekursiv, kann aber regul\u00e4r formuliert werden\n\n\nals \nInteger = Digit { Digit }.\n\n\nSyntax \u00e4quivalent\n\n\n\n\n\n\nScanner kann regul\u00e4re Sprachen, Parser kontextfreie Sprachen\n\n\nLexer ist endlicher Automat\n\n\n\n\n\n\nkontextsensitive Sprache wird begrenzt durch Semantic Checker abgedeckt\n\n\n\n\nMaximum Munch\n\n\n\n\nScanner absorbiert immer m\u00f6glichst viel\n\n\na.k.a. Regex \"greedy evaluation\"\n\n\n\n\n\n\nH\u00f6rt bei whitespace auf\n\n\n\n\nKommentare\n\n\n\n\nNicht schachtelbar -\n regul\u00e4re Ausdr\u00fccke\n\n\n\n\nTips f\u00fcr Scanner\n\n\n\n\nOverflow in Integers?\n\n\nAchtung: Min-value ist 1 \"gr\u00f6sser\" als max value!\n\n\nim Lexer nicht aufl\u00f6sbar, 1 zu gross erlauben\n\n\n\n\n\n\nNegative Zahlen als fix Token \n-\n und Integer scannen\n\n\nString-Scanner:\n\n\nEscaping beachten\n\n\nNewline beachten, String terminiert?\n\n\n\n\n\n\nEin \n/\n kann ein Kommentar oder ein Divide-Tag sein\n\n\nZeile / Position mitf\u00fchren (Position alleine reicht)\n\n\n\n\nFehlerbehandlung\n\n\n\n\nError-Tokens zur\u00fcck liefern, damit nicht direkt beim ersten Fehler abgebrochen wird\n\n\nBraucht aber eine Korrektur", 
            "title": "Lexer"
        }, 
        {
            "location": "/combau/lexer/#lexer", 
            "text": "", 
            "title": "Lexer"
        }, 
        {
            "location": "/combau/lexer/#trailing-else-problem", 
            "text": "Nicht eindeutige Syntax  Java umgeht das mit separat definiertem \"StatementNoShortIf\"", 
            "title": "Trailing else problem"
        }, 
        {
            "location": "/combau/lexer/#lexikalische-analyse", 
            "text": "Analyse von Terminalsymbolen zu Tokens  Token = \"Terminalsymbol\"    Von Charakter-Stream zu Token-Stream  Fasst mehrere Textzeichen zusammen zu Tokens  Eliminiert Whitespaces und Code-Kommentare  Whitespace ist aber relevant, um Tokens zu trennen  Kommentare k\u00f6nnen z.B. f\u00fcr Refactoring-Tools relevant sein    Merkt Position von Tokens im Code f\u00fcr Fehlermeldung und Debugging", 
            "title": "Lexikalische Analyse"
        }, 
        {
            "location": "/combau/lexer/#nutzer-fur-parser", 
            "text": "Parser arbeitet nur mit Tokens  Lookahead pro Symbol (nur n\u00e4chstes Symbol)", 
            "title": "Nutzer f\u00fcr Parser"
        }, 
        {
            "location": "/combau/lexer/#tokens", 
            "text": "Keywords sind reservierte Begriffe  Interpunktionen wie  ; ,  { ,  ]  etc.  Identifiers sind \"custom\" tokens wie Variablennamen (die keine keywords sein d\u00fcrfen)  Reservierte typennamen und Werte (true, false, ...) nicht als fixe Tokens scannen, sondern als Identifier", 
            "title": "Tokens"
        }, 
        {
            "location": "/combau/lexer/#regulare-sprachen", 
            "text": "Scanner / Lexer versteht nur regul\u00e4re Sprachen  in EBNF ohne Rekursion m\u00f6glich = regul\u00e4r  = als eine EBNF-Regel formulierbar    \u00ccnteger = Digit [ Integer ]  ist rekursiv, kann aber regul\u00e4r formuliert werden  als  Integer = Digit { Digit }.  Syntax \u00e4quivalent    Scanner kann regul\u00e4re Sprachen, Parser kontextfreie Sprachen  Lexer ist endlicher Automat    kontextsensitive Sprache wird begrenzt durch Semantic Checker abgedeckt", 
            "title": "Regul\u00e4re Sprachen"
        }, 
        {
            "location": "/combau/lexer/#maximum-munch", 
            "text": "Scanner absorbiert immer m\u00f6glichst viel  a.k.a. Regex \"greedy evaluation\"    H\u00f6rt bei whitespace auf", 
            "title": "Maximum Munch"
        }, 
        {
            "location": "/combau/lexer/#kommentare", 
            "text": "Nicht schachtelbar -  regul\u00e4re Ausdr\u00fccke", 
            "title": "Kommentare"
        }, 
        {
            "location": "/combau/lexer/#tips-fur-scanner", 
            "text": "Overflow in Integers?  Achtung: Min-value ist 1 \"gr\u00f6sser\" als max value!  im Lexer nicht aufl\u00f6sbar, 1 zu gross erlauben    Negative Zahlen als fix Token  -  und Integer scannen  String-Scanner:  Escaping beachten  Newline beachten, String terminiert?    Ein  /  kann ein Kommentar oder ein Divide-Tag sein  Zeile / Position mitf\u00fchren (Position alleine reicht)", 
            "title": "Tips f\u00fcr Scanner"
        }, 
        {
            "location": "/combau/lexer/#fehlerbehandlung", 
            "text": "Error-Tokens zur\u00fcck liefern, damit nicht direkt beim ersten Fehler abgebrochen wird  Braucht aber eine Korrektur", 
            "title": "Fehlerbehandlung"
        }, 
        {
            "location": "/combau/parser/", 
            "text": "Parser\n\n\nQuiz letzte Woche\n\n\n\n\nLexer liefert nur den regul\u00e4ren Anteil\n\n\nKeine rekursive Syntax-Elemente, bzw. Elemente, die _nur rekursiv ausdruckbar sind\n\n\n\n\n\n\n\n\nTop-Down Parser\n\n\n\n\nInput: Terminalsymbole, Output: Syntaxbaum\n\n\nKann nur kontextfreie Sprache\n\n\nz.B. nicht, ob Variable deklariert ist, oder Parameter auf Argumente passen, type checking\n\n\nDiese sind kontextabh\u00e4ngig\n\n\n\n\n\n\nDer Parser muss eine Ableitung der Syntaxregeln finden, um einen gegebenen Input herzuleiten\n\n\nQuasi eine Ableitung r\u00fcckw\u00e4rts, von Token zu einer Regel\n\n\nDiese Woche: Syntax-Check, n\u00e4chste Woche Syntaxbaum\n\n\n\n\nSyntax-Baum\n\n\n\n\nKonkreter Syntax-Baum (Parse Tree) befolgt die Syntax genau\n\n\nAbstract Syntax-Tree (AST) kann unwichtige Details auslassen\n\n\nz.B. Klammern weg lassen\n\n\n\n\n\n\nAST kann nicht automatisch erzeugt werden, \"nach Gusto\" des Entwicklers\n\n\nSelber implementierte Parser k\u00f6nnen direkt AST liefern\n\n\n\n\nTop-Down vs. Bottom-Up\n\n\n\n\nTop-Down: Zuerst \"linke Seite\" der Regel anwenden, bis Eingabetext rauskommt\n\n\nImmer von links her aufl\u00f6sen\n\n\n\n\n\n\nBottom-Up: Mit Eingabetext beginnen, und Regeln darauf anwenden, bis man zum \"Startsymbol\" kommt\n\n\nUmgekehrt zum Top-Down Parsing\n\n\n\n\n\n\n\n\nRecursive Decent\n\n\n\n\nWir nutzen den Stack der Methodenaufrufe als \"Push-Down Automat\"\n\n\nPro Nicht-terminalsymbol eine Methode\n\n\nWenn ein Nicht-Terminalsymbol in Syntax (rechte Seite) vorkommt, wird die entsprechende Methode aufgerufen\n\n\nMethoden k\u00f6nnen sich gegenseitig rekursiv aufrufen\n\n\nGibt keine Entscheidungsprobleme bei Top-Down (zielorientiert)\n\n\nAnderer Ansatz, wenn das nicht geht: Produktion ausprobieren und bei Fehler \"backtracken\" (exponentielle Laufzeit)\n\n\n\n\n\n\n\n\nTools und Implementation\n\n\n\n\nOne Token lookahead reicht aus\n\n\nMomentan geben die Methoden \nvoid\n zur\u00fcck, wo sp\u00e4ter ein Syntaxbaum erstellt wird\n\n\nNur Syntax-Check\n\n\n\n\n\n\nF\u00fcr nicht-terminal-Symbole braucht es z.T. ein weiteres Lookahead\n\n\nM\u00f6gliche Terminalsymbole erfassen, die in einem nicht-terminal-symbol als erstes vorkommen k\u00f6nnen: \nFIRST\n Set\n\n\nFIRST-Sets k\u00f6nnen Vereinigungen von \"untergeordneten\" NT-Symbolen haben\n\n\nWenn zwei NT-Symbole nicht-disjunkte FIRST-Mengen haben, reicht ein One-Token-Lookahead nicht mehr aus, da nicht entschieden werden kann\n\n\nBraucht weiteres Lookahead, dann irgendwann drei, etc.\n\n\nStattdessen Syntax \"umformen\" f\u00fcr Parser\n\n\nF\u00fcr beide Regeln eine eigene Regeln erfassen und das Gemeinsame zusammen ziehen\n\n\n\n\n\n\n\n\n\n\n\n\nLinksrekursion\n\n\n\n\nz.B. \nSequence = Sequence [ Statement ]\n\n\nGibt bei Implementation bei Recursive Decent endlose Rekursion\n\n\nBottom-Up Parser k\u00f6nnen damit umgehen\n\n\nUmschreiben nach \nSequence = { Statement }\n\n\n\n\nSyntaxbaum\n\n\n\n\nStatement-Block ist ein Spezialfall von Statement, in anderen Sprachen ist ein Statement-Block auch ein Statement\n\n\nAchten auf Assoziativit\u00e4t bei Expressions\n\n\n\n\n\n\n\n\n\n\nFehlerbehandlung\n\n\n\n\nNur h\u00e4ufige Fehler korrigieren\n\n\nBasiert immer auf Hypothese, es k\u00f6nnen leicht Folgefehler entstehen\n\n\nAndere Fehler wie inkompatible Typen, falsche Argumentliste, etc. werden im Semantic Checker behandelt\n\n\n\n\nAttributierte Grammatiken\n\n\n\n\nEBNF-Grammatiken mit kontext-sensitiven Attributen erg\u00e4nzen\n\n\nSemantische Checks oder Erzeugen des AST\n\n\nWrite()\n ist eine Aktion und gibt lediglich etwas auf die Konsole aus\n\n\nAusgabe Folie 22: `1 2 - 3 4 - +\n\n\nPostfix-Notation wie bei HP Taschenrechner\n\n\n\n\n\n\nDie Aktionen werden immer zum Schluss \"der Parse-Methode\" ausgef\u00fchrt\n\n\nDer Parser kann auch direkt statische Ausdr\u00fccke evaluieren\n\n\nDirekt Syntaxbaum erzeugen mit \nnew BinaryExpression(...)\n etc. direkt im Attribut\n\n\nS-attributiert (synthetisiert): Attribute lesen nur Parameter von Teilregeln (rechte Seite)\n\n\nL-attributiert (Ererbt): Attribut kann auch \"linke\" Seite lesen\n\n\nEs kann alles in Grammatik beschrieben werden, in der Praxis ist dies aber un\u00fcbersichtlich und kompliziert\n\n\n\n\nBottom-Up Parser (LR-Parser)\n\n\n\n\nAnsatz: Tokenstream nehmen und \"zusammenfalten\" zu Syntaxbaum\n\n\nNach jedem gelesenen Symbol pr\u00fcfen, ob die Folge einer Regel entspricht\n\n\nWenn ja, \"Reduce\"\n\n\nWenn nein, das n\u00e4chste Zeichen auslesen (shift)\n\n\n\n\n\n\nAm Schluss muss das Startsymbol \u00fcbrig bleiben, sonst Syntaxfehler\n\n\nEs kann zu Entscheidungsschwierigkeiten kommen: \"Shift-reduce\" / \"Reduce-Reduce\" Probleme\n\n\nGrammatik anpassen oder \"von Hand\"\n\n\n\n\n\n\nLR ist \"m\u00e4chtiger\" als LL-Parser\n\n\nz.B. Linksrekursion", 
            "title": "Parser"
        }, 
        {
            "location": "/combau/parser/#parser", 
            "text": "", 
            "title": "Parser"
        }, 
        {
            "location": "/combau/parser/#quiz-letzte-woche", 
            "text": "Lexer liefert nur den regul\u00e4ren Anteil  Keine rekursive Syntax-Elemente, bzw. Elemente, die _nur rekursiv ausdruckbar sind", 
            "title": "Quiz letzte Woche"
        }, 
        {
            "location": "/combau/parser/#top-down-parser", 
            "text": "Input: Terminalsymbole, Output: Syntaxbaum  Kann nur kontextfreie Sprache  z.B. nicht, ob Variable deklariert ist, oder Parameter auf Argumente passen, type checking  Diese sind kontextabh\u00e4ngig    Der Parser muss eine Ableitung der Syntaxregeln finden, um einen gegebenen Input herzuleiten  Quasi eine Ableitung r\u00fcckw\u00e4rts, von Token zu einer Regel  Diese Woche: Syntax-Check, n\u00e4chste Woche Syntaxbaum", 
            "title": "Top-Down Parser"
        }, 
        {
            "location": "/combau/parser/#syntax-baum", 
            "text": "Konkreter Syntax-Baum (Parse Tree) befolgt die Syntax genau  Abstract Syntax-Tree (AST) kann unwichtige Details auslassen  z.B. Klammern weg lassen    AST kann nicht automatisch erzeugt werden, \"nach Gusto\" des Entwicklers  Selber implementierte Parser k\u00f6nnen direkt AST liefern", 
            "title": "Syntax-Baum"
        }, 
        {
            "location": "/combau/parser/#top-down-vs-bottom-up", 
            "text": "Top-Down: Zuerst \"linke Seite\" der Regel anwenden, bis Eingabetext rauskommt  Immer von links her aufl\u00f6sen    Bottom-Up: Mit Eingabetext beginnen, und Regeln darauf anwenden, bis man zum \"Startsymbol\" kommt  Umgekehrt zum Top-Down Parsing", 
            "title": "Top-Down vs. Bottom-Up"
        }, 
        {
            "location": "/combau/parser/#recursive-decent", 
            "text": "Wir nutzen den Stack der Methodenaufrufe als \"Push-Down Automat\"  Pro Nicht-terminalsymbol eine Methode  Wenn ein Nicht-Terminalsymbol in Syntax (rechte Seite) vorkommt, wird die entsprechende Methode aufgerufen  Methoden k\u00f6nnen sich gegenseitig rekursiv aufrufen  Gibt keine Entscheidungsprobleme bei Top-Down (zielorientiert)  Anderer Ansatz, wenn das nicht geht: Produktion ausprobieren und bei Fehler \"backtracken\" (exponentielle Laufzeit)", 
            "title": "Recursive Decent"
        }, 
        {
            "location": "/combau/parser/#tools-und-implementation", 
            "text": "One Token lookahead reicht aus  Momentan geben die Methoden  void  zur\u00fcck, wo sp\u00e4ter ein Syntaxbaum erstellt wird  Nur Syntax-Check    F\u00fcr nicht-terminal-Symbole braucht es z.T. ein weiteres Lookahead  M\u00f6gliche Terminalsymbole erfassen, die in einem nicht-terminal-symbol als erstes vorkommen k\u00f6nnen:  FIRST  Set  FIRST-Sets k\u00f6nnen Vereinigungen von \"untergeordneten\" NT-Symbolen haben  Wenn zwei NT-Symbole nicht-disjunkte FIRST-Mengen haben, reicht ein One-Token-Lookahead nicht mehr aus, da nicht entschieden werden kann  Braucht weiteres Lookahead, dann irgendwann drei, etc.  Stattdessen Syntax \"umformen\" f\u00fcr Parser  F\u00fcr beide Regeln eine eigene Regeln erfassen und das Gemeinsame zusammen ziehen", 
            "title": "Tools und Implementation"
        }, 
        {
            "location": "/combau/parser/#linksrekursion", 
            "text": "z.B.  Sequence = Sequence [ Statement ]  Gibt bei Implementation bei Recursive Decent endlose Rekursion  Bottom-Up Parser k\u00f6nnen damit umgehen  Umschreiben nach  Sequence = { Statement }", 
            "title": "Linksrekursion"
        }, 
        {
            "location": "/combau/parser/#syntaxbaum", 
            "text": "Statement-Block ist ein Spezialfall von Statement, in anderen Sprachen ist ein Statement-Block auch ein Statement  Achten auf Assoziativit\u00e4t bei Expressions", 
            "title": "Syntaxbaum"
        }, 
        {
            "location": "/combau/parser/#fehlerbehandlung", 
            "text": "Nur h\u00e4ufige Fehler korrigieren  Basiert immer auf Hypothese, es k\u00f6nnen leicht Folgefehler entstehen  Andere Fehler wie inkompatible Typen, falsche Argumentliste, etc. werden im Semantic Checker behandelt", 
            "title": "Fehlerbehandlung"
        }, 
        {
            "location": "/combau/parser/#attributierte-grammatiken", 
            "text": "EBNF-Grammatiken mit kontext-sensitiven Attributen erg\u00e4nzen  Semantische Checks oder Erzeugen des AST  Write()  ist eine Aktion und gibt lediglich etwas auf die Konsole aus  Ausgabe Folie 22: `1 2 - 3 4 - +  Postfix-Notation wie bei HP Taschenrechner    Die Aktionen werden immer zum Schluss \"der Parse-Methode\" ausgef\u00fchrt  Der Parser kann auch direkt statische Ausdr\u00fccke evaluieren  Direkt Syntaxbaum erzeugen mit  new BinaryExpression(...)  etc. direkt im Attribut  S-attributiert (synthetisiert): Attribute lesen nur Parameter von Teilregeln (rechte Seite)  L-attributiert (Ererbt): Attribut kann auch \"linke\" Seite lesen  Es kann alles in Grammatik beschrieben werden, in der Praxis ist dies aber un\u00fcbersichtlich und kompliziert", 
            "title": "Attributierte Grammatiken"
        }, 
        {
            "location": "/combau/parser/#bottom-up-parser-lr-parser", 
            "text": "Ansatz: Tokenstream nehmen und \"zusammenfalten\" zu Syntaxbaum  Nach jedem gelesenen Symbol pr\u00fcfen, ob die Folge einer Regel entspricht  Wenn ja, \"Reduce\"  Wenn nein, das n\u00e4chste Zeichen auslesen (shift)    Am Schluss muss das Startsymbol \u00fcbrig bleiben, sonst Syntaxfehler  Es kann zu Entscheidungsschwierigkeiten kommen: \"Shift-reduce\" / \"Reduce-Reduce\" Probleme  Grammatik anpassen oder \"von Hand\"    LR ist \"m\u00e4chtiger\" als LL-Parser  z.B. Linksrekursion", 
            "title": "Bottom-Up Parser (LR-Parser)"
        }, 
        {
            "location": "/combau/semantic_analysis/", 
            "text": "Semantische Analyse\n\n\nQuiz\n\n\n\n\nIst syntaktisch korrekt, weil ein \nif\n als condition eine Expression erwartet\n\n\nAber semantisch falsch, bool nicht addierbar etc.\n\n\nDies sind \nkontextsensitive\n Regeln\n\n\n\n\n\n\n\n\nSemantic Checker\n\n\n\n\nInput: AST oder konkreter Syntaxtree\n\n\nOutput: AST + Symboltabelle\n\n\nPr\u00fcfen, dass das Programm gem\u00e4ss Sprachregeln \"Sinn macht\"\n\n\nDeklarationen pr\u00fcfen (eindeutig und nicht mehrfach)\n\n\nTypen (Typregeln sind erf\u00fcllt)\n\n\nMethod-Calls (Argumente und Parameter sind kompatibel)\n\n\nUnd mehr...\n\n\n\n\n\n\nTransformiere Programm, so dass Code Generation einfach wird\n\n\nSyntaxbaum umstellen\n\n\nz.B. Vereinheitlichen von verschiedenen Loops, z.B. aus for- einen while-loop\n\n\nArray Boundary Check\n\n\nImplizite Casts\n\n\nusw.\n\n\n\n\n\n\n\n\nSymboltabelle\n\n\n\n\nDatenstruktur zur Verwaltung von Deklarationen\n\n\nZu jedem Namen ist der Scope angegeben\n\n\nScopes k\u00f6nnen rekursiv sein, z.B. Methode -\n Methode etc.\n\n\nScoping auch wichtig bei z.B. loops\n\n\n\n\nShadowing\n\n\n\n\n\u00dcberdecken von Deklarationen in \u00e4usserem Scope durch Defintion in innerem Scope\n\n\nIn Rappi-sharp m\u00f6glich\n\n\nUnterschied zu \"Hiding\": Beim Hiding verdecken Methoden/Variablen in einer Unterklasse die Deklaration in der Superklasse\n\n\nShadowing in \n\n\n\n\nGlobal Scope\n\n\n\n\nEs gibt einen global Scope\n\n\nBei uns k\u00f6nnen dort nur Klassen vorkommen\n\n\n\n\n\n\nKeywords wie \ntrue\n, \nint\n, \nbool\n k\u00f6nnen auch dort definiert werden\n\n\n\n\nDesign der Symboltabelle\n\n\n\n\nCompilationUnit\n ist der \"global\" Scope\n\n\nIm ersten Schritt werden die Deklarationen aufgel\u00f6st, erste danach werden Typen aufgel\u00f6st\n\n\nWeil w\u00e4hrend dem Durchlaufen Typen erst sp\u00e4ter deklariert werden k\u00f6nnten\n\n\n\n\n\n\nZu einer lokalen Variable wird dazu gespeichert, in welchen Statements die Variable \"lebt\"\n\n\nSp\u00e4testens jetzt muss gepr\u00fcft werden, dass \nint\n, \nbool\n etc nicht als Identifier verwendet werden!\n\n\nnull\n muss speziell behandelt werden\n\n\nEs gibt ein Dictionary, das Symbole zu Knoten-Referenzen mappt.\n\n\n\n\nVorgehen\n\n\n\n\nSymboltabelle aufbauen\n\n\nTypen aufl\u00f6sen\n\n\nAST durchlaufen und mit Symboltabelle verbinden\n\n\nAlle Vorkommenden Identifier verlinken mit entsprechendem Symbol \n\n\n\n\n\n\n(Unsere Aufgabe) Typen in AST bestimmen\n\n\n\n\nNamensaufl\u00f6sung\n\n\n\n\nz.B. Typen aufl\u00f6sen\n\n\nZuerst suche im innersten Scope, dann im n\u00e4chst \u00e4usseren Scope, usw. rekursiv\n\n\nSuche mit \nFind\n Method auf Symboltabelle\n\n\n\n\nType Checking\n\n\n\n\nImportant\n\n\nWichtig f\u00fcr \u00dcbung: Folie 32, Folie 36 Punkte 2, 4-7, 9, Folien 38-42\n\n\n\n\n\n\nF\u00fcr jede Expression den Typ bestimmen\n\n\nInsbesondere Binary/Binary Expressions: Typen checken\n\n\nAuch z.B. bei \nif\n: Ist condition ein bool?\n\n\n\n\nAblauf\n\n\n\n\nPost-Order-Traversierung\n\n\nZuerst child-nodes aufl\u00f6sen\n\n\n\n\n\n\nAST nicht ver\u00e4ndern, sondern z.B. Symboltabelle \nFixType()\n aufrufen\n\n\nNach dem Aufl\u00f6sen folgt das Checking\n\n\nz.B. Array length read-only, noch selbst implementieren\n\n\n\n\n\n\nBei Zuweisungen: Pr\u00fcfen, ob rechte und linke Seite gleichen Typ haben\n\n\nAusser bei Polymorphismus und \nnull\n\n\nGleiches Prinzip bei Methoden-Aufrufen\n\n\n\n\n\n\n\n\nStatische Analyse\n\n\n\n\nChecks wie Array-Bounds sind nicht allgemein entscheidbar\n\n\nKann vom Compiler transformiert werden, z.B. neue Statements einf\u00fcgen\n\n\n\n\n\n\nMuss bei einer Runtime aber sowieso \u00fcberpr\u00fcft werden (Sicherheit), deshalb lohnt es sich hier nicht", 
            "title": "Semantische Analyse"
        }, 
        {
            "location": "/combau/semantic_analysis/#semantische-analyse", 
            "text": "", 
            "title": "Semantische Analyse"
        }, 
        {
            "location": "/combau/semantic_analysis/#quiz", 
            "text": "Ist syntaktisch korrekt, weil ein  if  als condition eine Expression erwartet  Aber semantisch falsch, bool nicht addierbar etc.  Dies sind  kontextsensitive  Regeln", 
            "title": "Quiz"
        }, 
        {
            "location": "/combau/semantic_analysis/#semantic-checker", 
            "text": "Input: AST oder konkreter Syntaxtree  Output: AST + Symboltabelle  Pr\u00fcfen, dass das Programm gem\u00e4ss Sprachregeln \"Sinn macht\"  Deklarationen pr\u00fcfen (eindeutig und nicht mehrfach)  Typen (Typregeln sind erf\u00fcllt)  Method-Calls (Argumente und Parameter sind kompatibel)  Und mehr...    Transformiere Programm, so dass Code Generation einfach wird  Syntaxbaum umstellen  z.B. Vereinheitlichen von verschiedenen Loops, z.B. aus for- einen while-loop  Array Boundary Check  Implizite Casts  usw.", 
            "title": "Semantic Checker"
        }, 
        {
            "location": "/combau/semantic_analysis/#symboltabelle", 
            "text": "Datenstruktur zur Verwaltung von Deklarationen  Zu jedem Namen ist der Scope angegeben  Scopes k\u00f6nnen rekursiv sein, z.B. Methode -  Methode etc.  Scoping auch wichtig bei z.B. loops", 
            "title": "Symboltabelle"
        }, 
        {
            "location": "/combau/semantic_analysis/#shadowing", 
            "text": "\u00dcberdecken von Deklarationen in \u00e4usserem Scope durch Defintion in innerem Scope  In Rappi-sharp m\u00f6glich  Unterschied zu \"Hiding\": Beim Hiding verdecken Methoden/Variablen in einer Unterklasse die Deklaration in der Superklasse  Shadowing in", 
            "title": "Shadowing"
        }, 
        {
            "location": "/combau/semantic_analysis/#global-scope", 
            "text": "Es gibt einen global Scope  Bei uns k\u00f6nnen dort nur Klassen vorkommen    Keywords wie  true ,  int ,  bool  k\u00f6nnen auch dort definiert werden", 
            "title": "Global Scope"
        }, 
        {
            "location": "/combau/semantic_analysis/#design-der-symboltabelle", 
            "text": "CompilationUnit  ist der \"global\" Scope  Im ersten Schritt werden die Deklarationen aufgel\u00f6st, erste danach werden Typen aufgel\u00f6st  Weil w\u00e4hrend dem Durchlaufen Typen erst sp\u00e4ter deklariert werden k\u00f6nnten    Zu einer lokalen Variable wird dazu gespeichert, in welchen Statements die Variable \"lebt\"  Sp\u00e4testens jetzt muss gepr\u00fcft werden, dass  int ,  bool  etc nicht als Identifier verwendet werden!  null  muss speziell behandelt werden  Es gibt ein Dictionary, das Symbole zu Knoten-Referenzen mappt.", 
            "title": "Design der Symboltabelle"
        }, 
        {
            "location": "/combau/semantic_analysis/#vorgehen", 
            "text": "Symboltabelle aufbauen  Typen aufl\u00f6sen  AST durchlaufen und mit Symboltabelle verbinden  Alle Vorkommenden Identifier verlinken mit entsprechendem Symbol     (Unsere Aufgabe) Typen in AST bestimmen", 
            "title": "Vorgehen"
        }, 
        {
            "location": "/combau/semantic_analysis/#namensauflosung", 
            "text": "z.B. Typen aufl\u00f6sen  Zuerst suche im innersten Scope, dann im n\u00e4chst \u00e4usseren Scope, usw. rekursiv  Suche mit  Find  Method auf Symboltabelle", 
            "title": "Namensaufl\u00f6sung"
        }, 
        {
            "location": "/combau/semantic_analysis/#type-checking", 
            "text": "Important  Wichtig f\u00fcr \u00dcbung: Folie 32, Folie 36 Punkte 2, 4-7, 9, Folien 38-42    F\u00fcr jede Expression den Typ bestimmen  Insbesondere Binary/Binary Expressions: Typen checken  Auch z.B. bei  if : Ist condition ein bool?", 
            "title": "Type Checking"
        }, 
        {
            "location": "/combau/semantic_analysis/#ablauf", 
            "text": "Post-Order-Traversierung  Zuerst child-nodes aufl\u00f6sen    AST nicht ver\u00e4ndern, sondern z.B. Symboltabelle  FixType()  aufrufen  Nach dem Aufl\u00f6sen folgt das Checking  z.B. Array length read-only, noch selbst implementieren    Bei Zuweisungen: Pr\u00fcfen, ob rechte und linke Seite gleichen Typ haben  Ausser bei Polymorphismus und  null  Gleiches Prinzip bei Methoden-Aufrufen", 
            "title": "Ablauf"
        }, 
        {
            "location": "/combau/semantic_analysis/#statische-analyse", 
            "text": "Checks wie Array-Bounds sind nicht allgemein entscheidbar  Kann vom Compiler transformiert werden, z.B. neue Statements einf\u00fcgen    Muss bei einer Runtime aber sowieso \u00fcberpr\u00fcft werden (Sicherheit), deshalb lohnt es sich hier nicht", 
            "title": "Statische Analyse"
        }, 
        {
            "location": "/combau/code_generation/", 
            "text": "Code Generierung\n\n\nOptimization\n\n\n\n\nZwischendarstellung (AST) transformieren f\u00fcr effizienteren Code\n\n\nz.B konstante Expressions, leere Statement-Bl\u00f6cke, etc.\n\n\nWird bei uns noch ausgelassen\n\n\nKann auch sp\u00e4ter, z.B. im JIT geschehen\n\n\n\n\nIntermediate Language\n\n\n\n\nZiel bei uns: Erzeugung von Code f\u00fcr eine VM\n\n\nZwischendarstellung ist die Schnittstelle zum \"Backend\", in diesem Fall eine Runtime\n\n\nMehrere Frontends: Multi-Language\n\n\nMehrere Backends: Multi-Platform\n\n\n\n\n\n\n\n\nUnsere Zielmaschine\n\n\n\n\nSubset von .NET IL\n\n\nVirtueller Stack-Prozessor\n\n\nKeine Register\n\n\n\n\n\n\n\"goto\"-machine\n\n\nKeine loops, nur \"flacher\" Code mit Branches\n\n\n\n\n\n\nMetadaten: Was sind unsere Klassen, Variablen, Typen, etc.?\n\n\nU.a. f\u00fcr Linking, Querreferenzen von anderen Libraries / Binaries\n\n\nReferenzen f\u00fcr GC \n\n\n\n\n\n\n\n\nVirtual Stack Machine\n\n\n\n\nStack in der Prozedur\n\n\nOperanden lesen (pop) und Ergebnis schreiben (push)\n\n\nErster Pop ist right-hand-side der Operation\n\n\n\n\n\n\nJede Instruktion hat gewisse Anzahl Pops und Pushes\n\n\nStack ist vor und nach der Methode \"leer\"\n\n\nKann auch alles in einem Stack ausgef\u00fchrt werden\n\n\n\n\n\n\nLokale Variablen / Parameter werden durchnummeriert\n\n\nBeispiel Auswertung: \nx = x * (7 + 11)\n\n\nIm Unterschied zu Java / .NET haben wir konkrete Boolean-Werte\n\n\nSonst w\u00e4ren es 0/1 integers\n\n\nand\n und \nor\n-Operators m\u00fcssen mit Branches nachgebaut werden (\u00e4quivalent zu if-else)\n\n\n\n\n\n\nBeispiel Boolean: \nb = !a\n\n\n\n\nKontrollfluss\n\n\n\n\nBranch to Label Instruktionen\n\n\nConditional Instruktionen (z.B. \nbrfalse\n), um zu anderen Branches zu springen\n\n\n\n\nIL-Generierung\n\n\n\n\nBuilder Pattern\n\n\nSerialisierung in XML (bei uns, f\u00fcr Komfort)\n\n\nZuerst Metadaten mit Symboltabelle erstellen\n\n\nAST Traversieren mit Visitor und Instruktionen erzeugen\n\n\nLabels werden zuerst erstellt (\nCreateLabel()\n) und erst sp\u00e4ter an den IL-Code \"attached\" (\nSetLabel()\n)\n\n\nLabels werden am Schluss \u00fcbersetzt in relative Sprungstellen (in Anzahl Instruktionen)\n\n\n\n\nCode-Templates\n\n\n\n\nMit Pattern-Matching Muster im AST erkennen\n\n\nz.B. wenn \n+\n kommt, generieren wir \nadd\n\n\nPost-Order-Traversierung und jeweils Pattern erkennen\n\n\nKleine Optimierungen m\u00f6glich\n\n\nPattern-Erkennung schwieriger, z.B. um \nif\n und \nif-else\n zu unterscheiden\n\n\nBin\u00e4re Operatoren mit Booleans als \nif-else\n behandeln", 
            "title": "Code Generierung"
        }, 
        {
            "location": "/combau/code_generation/#code-generierung", 
            "text": "", 
            "title": "Code Generierung"
        }, 
        {
            "location": "/combau/code_generation/#optimization", 
            "text": "Zwischendarstellung (AST) transformieren f\u00fcr effizienteren Code  z.B konstante Expressions, leere Statement-Bl\u00f6cke, etc.  Wird bei uns noch ausgelassen  Kann auch sp\u00e4ter, z.B. im JIT geschehen", 
            "title": "Optimization"
        }, 
        {
            "location": "/combau/code_generation/#intermediate-language", 
            "text": "Ziel bei uns: Erzeugung von Code f\u00fcr eine VM  Zwischendarstellung ist die Schnittstelle zum \"Backend\", in diesem Fall eine Runtime  Mehrere Frontends: Multi-Language  Mehrere Backends: Multi-Platform", 
            "title": "Intermediate Language"
        }, 
        {
            "location": "/combau/code_generation/#unsere-zielmaschine", 
            "text": "Subset von .NET IL  Virtueller Stack-Prozessor  Keine Register    \"goto\"-machine  Keine loops, nur \"flacher\" Code mit Branches    Metadaten: Was sind unsere Klassen, Variablen, Typen, etc.?  U.a. f\u00fcr Linking, Querreferenzen von anderen Libraries / Binaries  Referenzen f\u00fcr GC", 
            "title": "Unsere Zielmaschine"
        }, 
        {
            "location": "/combau/code_generation/#virtual-stack-machine", 
            "text": "Stack in der Prozedur  Operanden lesen (pop) und Ergebnis schreiben (push)  Erster Pop ist right-hand-side der Operation    Jede Instruktion hat gewisse Anzahl Pops und Pushes  Stack ist vor und nach der Methode \"leer\"  Kann auch alles in einem Stack ausgef\u00fchrt werden    Lokale Variablen / Parameter werden durchnummeriert  Beispiel Auswertung:  x = x * (7 + 11)  Im Unterschied zu Java / .NET haben wir konkrete Boolean-Werte  Sonst w\u00e4ren es 0/1 integers  and  und  or -Operators m\u00fcssen mit Branches nachgebaut werden (\u00e4quivalent zu if-else)    Beispiel Boolean:  b = !a", 
            "title": "Virtual Stack Machine"
        }, 
        {
            "location": "/combau/code_generation/#kontrollfluss", 
            "text": "Branch to Label Instruktionen  Conditional Instruktionen (z.B.  brfalse ), um zu anderen Branches zu springen", 
            "title": "Kontrollfluss"
        }, 
        {
            "location": "/combau/code_generation/#il-generierung", 
            "text": "Builder Pattern  Serialisierung in XML (bei uns, f\u00fcr Komfort)  Zuerst Metadaten mit Symboltabelle erstellen  AST Traversieren mit Visitor und Instruktionen erzeugen  Labels werden zuerst erstellt ( CreateLabel() ) und erst sp\u00e4ter an den IL-Code \"attached\" ( SetLabel() )  Labels werden am Schluss \u00fcbersetzt in relative Sprungstellen (in Anzahl Instruktionen)", 
            "title": "IL-Generierung"
        }, 
        {
            "location": "/combau/code_generation/#code-templates", 
            "text": "Mit Pattern-Matching Muster im AST erkennen  z.B. wenn  +  kommt, generieren wir  add  Post-Order-Traversierung und jeweils Pattern erkennen  Kleine Optimierungen m\u00f6glich  Pattern-Erkennung schwieriger, z.B. um  if  und  if-else  zu unterscheiden  Bin\u00e4re Operatoren mit Booleans als  if-else  behandeln", 
            "title": "Code-Templates"
        }, 
        {
            "location": "/combau/virtual_machine/", 
            "text": "Virtual Machine\n\n\nVirtual Machine\n\n\n\n\nHypothetische Maschine, die die IL versteht\n\n\n\"Virtueller Prozessor\" mit IL als Instruktionssatz\n\n\nBietet Mehrsprachigkeit, Multi Platform\n\n\nTrennt Compiler von Laufzeit\n\n\n\n\nLoader\n\n\n\n\nL\u00e4dt IL in Speicher\n\n\nAlloziert Speicher\n\n\nAddress Relocation\n\n\nAdressen m\u00fcssen \"gefixt\" werden, weil Speicher nacheinander alloziert wird\n\n\n\n\n\n\nVerifier: Statische Analyse des Codes\n\n\nInitiiert Ausf\u00fchrung auf Interpreter / JIT\n\n\nIL-Code wird direkt in Speicher geladen\n\n\nMethodenaufrufe werden aufgel\u00f6st mit Deskriptoren (\"Fixup\")\n\n\n\n\n\n\n\n\nMetadaten\n\n\n\n\nTyp-Deskriptoren\n\n\n\u00c4hnlich Symboltabelle\n\n\nBeschreiben die Subtypen von Typen\n\n\nz.B. Field types von Klassen\n\n\n\n\n\n\n\n\nInterpreter\n\n\n\n\nInterpretiert den IL-Code\n\n\nProduziert Code f\u00fcr Hardware-Ausf\u00fchrung oder f\u00fcr JIT\n\n\nDer Prozess wird unterst\u00fctzt von Metadaten, Heap und Stacks\n\n\nInterpreter-Loop emuliert eine Instruktion nach der anderen\n\n\nInstruction Pointer kann vor- oder zur\u00fcck springen (z.B. bei Branches)\n\n\n\n\nCall Stack\n\n\n\n\nStack von Activation Frames\n\n\nActivation Frame ist der \"Datenraum\" einer Methode\n\n\nIn jedem Activation Frame befindet sich ein Evaluation Stack\n\n\n\n\n\n\nBei uns gibt es nur einen Call-Stack (single-threaded)\n\n\nStatische Methoden bei uns gehen auf .NET Call-Stack\n\n\n\n\nMethod-Call\n\n\n\n\nNoch \u00fcberpr\u00fcfen, ob die Methode auch auf dem richtigen Objekt aufgerufen wird\n\n\n\n\nMethod Return\n\n\n\n\nR\u00fcckgabetyp pr\u00fcfen\n\n\nPr\u00fcfen, ob Stack leer ist nach Return", 
            "title": "Virtual Machine"
        }, 
        {
            "location": "/combau/virtual_machine/#virtual-machine", 
            "text": "", 
            "title": "Virtual Machine"
        }, 
        {
            "location": "/combau/virtual_machine/#virtual-machine_1", 
            "text": "Hypothetische Maschine, die die IL versteht  \"Virtueller Prozessor\" mit IL als Instruktionssatz  Bietet Mehrsprachigkeit, Multi Platform  Trennt Compiler von Laufzeit", 
            "title": "Virtual Machine"
        }, 
        {
            "location": "/combau/virtual_machine/#loader", 
            "text": "L\u00e4dt IL in Speicher  Alloziert Speicher  Address Relocation  Adressen m\u00fcssen \"gefixt\" werden, weil Speicher nacheinander alloziert wird    Verifier: Statische Analyse des Codes  Initiiert Ausf\u00fchrung auf Interpreter / JIT  IL-Code wird direkt in Speicher geladen  Methodenaufrufe werden aufgel\u00f6st mit Deskriptoren (\"Fixup\")", 
            "title": "Loader"
        }, 
        {
            "location": "/combau/virtual_machine/#metadaten", 
            "text": "Typ-Deskriptoren  \u00c4hnlich Symboltabelle  Beschreiben die Subtypen von Typen  z.B. Field types von Klassen", 
            "title": "Metadaten"
        }, 
        {
            "location": "/combau/virtual_machine/#interpreter", 
            "text": "Interpretiert den IL-Code  Produziert Code f\u00fcr Hardware-Ausf\u00fchrung oder f\u00fcr JIT  Der Prozess wird unterst\u00fctzt von Metadaten, Heap und Stacks  Interpreter-Loop emuliert eine Instruktion nach der anderen  Instruction Pointer kann vor- oder zur\u00fcck springen (z.B. bei Branches)", 
            "title": "Interpreter"
        }, 
        {
            "location": "/combau/virtual_machine/#call-stack", 
            "text": "Stack von Activation Frames  Activation Frame ist der \"Datenraum\" einer Methode  In jedem Activation Frame befindet sich ein Evaluation Stack    Bei uns gibt es nur einen Call-Stack (single-threaded)  Statische Methoden bei uns gehen auf .NET Call-Stack", 
            "title": "Call Stack"
        }, 
        {
            "location": "/combau/virtual_machine/#method-call", 
            "text": "Noch \u00fcberpr\u00fcfen, ob die Methode auch auf dem richtigen Objekt aufgerufen wird", 
            "title": "Method-Call"
        }, 
        {
            "location": "/combau/virtual_machine/#method-return", 
            "text": "R\u00fcckgabetyp pr\u00fcfen  Pr\u00fcfen, ob Stack leer ist nach Return", 
            "title": "Method Return"
        }, 
        {
            "location": "/combau/polymorphism/", 
            "text": "Typ-Polymorphismus\n\n\nReview letzte Woche\n\n\n\n\nType-Tag wird ben\u00f6tigt f\u00fcr Dynamic Dispatch (vtables), Garbage Collector, Interpreter (type safety), type tests/casts\n\n\n\n\nSingle Inheritance\n\n\n\n\nZur Einfachheit nur Einfachvererbung\n\n\n\n\nCode Reuse\n\n\n\n\nSubklassen erben transitiv die Felder und Methoden der Basisklasse\n\n\nMemory Layout: Fields der Basisklasse zuerst, damit der Field index bei Polymorphismus gleich bleibt\n\n\n\n\n\n\nHiding: Variablen in Subklasse \u00fcberdecken Variablen in Basisklasse\n\n\nWird statisch aufgel\u00f6st\n\n\n\n\n\n\n\n\nTyp-Polymorphismus\n\n\n\n\nSubtyp ist auf Basistyp zuweisungskompatibel\n\n\nTyp wird dynamisch bestimmt anhand des Type-Tags\n\n\nVererbung kann beliebig tief verschachtelt sein\n\n\nIneffizient, die ganze Vererbungskette durch zu loopen f\u00fcr einen Check\n\n\n\n\n\n\nEs braucht eine fixe Struktur, in der die Vererbungshierarchie abgebildet wird, um den Check in konstanter Zeit zu machen\n\n\n\n\nEffiziente Codierung Vererbung\n\n\n\n\nJeder Typ-Deskriptor hat eine Tabelle der Basistypen in verschiedenen Stufen\n\n\nDie letzte Stufe zeigt auf sich selbst\n\n\nDie Vererbungshierarchien sind fest zu Compile-Time, daher weiss man direkt, in welcher Stufe ein Basistyp sein muss\n\n\nUnn\u00f6tige Type-Casts k\u00f6nnen vom Compiler direkt aufgel\u00f6st werden\n\n\nType-Tests bei \nnull\n evaluiert zu \nfalse\n\n\nType-Cast von \nnull\n ist erfolgreich\n\n\n\n\nVirtuelle Methoden / Dynamic Dispatch\n\n\n\n\nBeim Typ-Deskriptor wird eine Virtual Table hinterlegt\n\n\nJeder Eintrag zeigt auf die konkrete Methode, entweder von sich selbst oder von einer Basisklasse\n\n\nKann vom Compiler aufgel\u00f6st werden (bzw. bei uns vom Loader)\n\n\nMethoden der Basisklasse zuerst in vtable, dann stimmt die Reihenfolge bei Dynamic Dispatch direkt", 
            "title": "Typ-Polymorphismus"
        }, 
        {
            "location": "/combau/polymorphism/#typ-polymorphismus", 
            "text": "", 
            "title": "Typ-Polymorphismus"
        }, 
        {
            "location": "/combau/polymorphism/#review-letzte-woche", 
            "text": "Type-Tag wird ben\u00f6tigt f\u00fcr Dynamic Dispatch (vtables), Garbage Collector, Interpreter (type safety), type tests/casts", 
            "title": "Review letzte Woche"
        }, 
        {
            "location": "/combau/polymorphism/#single-inheritance", 
            "text": "Zur Einfachheit nur Einfachvererbung", 
            "title": "Single Inheritance"
        }, 
        {
            "location": "/combau/polymorphism/#code-reuse", 
            "text": "Subklassen erben transitiv die Felder und Methoden der Basisklasse  Memory Layout: Fields der Basisklasse zuerst, damit der Field index bei Polymorphismus gleich bleibt    Hiding: Variablen in Subklasse \u00fcberdecken Variablen in Basisklasse  Wird statisch aufgel\u00f6st", 
            "title": "Code Reuse"
        }, 
        {
            "location": "/combau/polymorphism/#typ-polymorphismus_1", 
            "text": "Subtyp ist auf Basistyp zuweisungskompatibel  Typ wird dynamisch bestimmt anhand des Type-Tags  Vererbung kann beliebig tief verschachtelt sein  Ineffizient, die ganze Vererbungskette durch zu loopen f\u00fcr einen Check    Es braucht eine fixe Struktur, in der die Vererbungshierarchie abgebildet wird, um den Check in konstanter Zeit zu machen", 
            "title": "Typ-Polymorphismus"
        }, 
        {
            "location": "/combau/polymorphism/#effiziente-codierung-vererbung", 
            "text": "Jeder Typ-Deskriptor hat eine Tabelle der Basistypen in verschiedenen Stufen  Die letzte Stufe zeigt auf sich selbst  Die Vererbungshierarchien sind fest zu Compile-Time, daher weiss man direkt, in welcher Stufe ein Basistyp sein muss  Unn\u00f6tige Type-Casts k\u00f6nnen vom Compiler direkt aufgel\u00f6st werden  Type-Tests bei  null  evaluiert zu  false  Type-Cast von  null  ist erfolgreich", 
            "title": "Effiziente Codierung Vererbung"
        }, 
        {
            "location": "/combau/polymorphism/#virtuelle-methoden-dynamic-dispatch", 
            "text": "Beim Typ-Deskriptor wird eine Virtual Table hinterlegt  Jeder Eintrag zeigt auf die konkrete Methode, entweder von sich selbst oder von einer Basisklasse  Kann vom Compiler aufgel\u00f6st werden (bzw. bei uns vom Loader)  Methoden der Basisklasse zuerst in vtable, dann stimmt die Reihenfolge bei Dynamic Dispatch direkt", 
            "title": "Virtuelle Methoden / Dynamic Dispatch"
        }, 
        {
            "location": "/combau/garbage_collection/", 
            "text": "Garbage Collection\n\n\nMemory Safety\n\n\n\n\nBei uns werden Metadaten vom .NET-GC abger\u00e4umt\n\n\nGC wird z.B. bei Webserver ben\u00f6tigt, wenn immer neue Objekte alloziert werden\n\n\nExplizite Freigabe (mit \ndelete\n) f\u00fchrt zu Dangling Pointers (zu fr\u00fche Freigabe) und Memory Leaks (zu sp\u00e4te / keine Freigabe)\n\n\n\n\nGarbage Collection\n\n\n\n\nLaufzeitsystem k\u00fcmmert sich um die Freigabe\n\n\nEs gibt mehrere Techniken dazu\n\n\nGarbage = Objekte, die \nnicht mehr erreichbar sind\n und daher nicht mehr gebraucht werden\n\n\n\n\nReference Counting\n\n\n\n\nNaive Variante von GC\n\n\nz.B. von Objective C implementiert, bei C++ shared pointers\n\n\nIdee: Eingehende Referenzen von einem Objekt z\u00e4hlen\n\n\nWenn die Zahl = 0 -\n Ist Garbage\n\n\nBei Zyklischen Abh\u00e4ngigkeiten ist Garbage = Reference Count 0 nicht gegeben\n\n\n\n\n\n\nUpdates sind teuer\n\n\nDie Reference Counts sind \"shared resources\", d.h. sie m\u00fcssen atomar geschrieben werden\n\n\n\n\n\n\nZyklische Strukturen werden nie zu Garbage, da sie sich immer gegenseitig (bzw. zyklisch) referenzieren\n\n\n= Memory Leak\n\n\nViele Strukturen sind zyklisch\n\n\nWird z.B. bei C++ mit \nweak_pointer\n gel\u00f6st\n\n\n\n\n\n\nVorteil: Deallokation ist deterministisch bei letzter Dereferenzierung\n\n\n\n\nGarbage Collector\n\n\n\n\nHeap wird analysiert und Garbage freigegeben\n\n\nHeap ist ein flacher Graph\n\n\nL\u00e4uft nicht-deterministisch\n\n\nGarbage sind Nodes im Graph, die vom \"Programm\" nicht mehr erreichbar sind\n\n\nLaufendes Programm ist \"Root-Set\"\n\n\nRoot-Set besteht aus allen Referenzen im aktiven Frame auf dem Call Stack\n\n\n\n\nMark \n Sweep\n\n\n\n\nMarkiere alle transitiven erreichbaren Objekte\n\n\nSweep: L\u00f6sche alle nicht markierte Objekte\n\n\nMit Tiefensuche alle Objekte von einem Root-Objekt aus traversieren\n\n\nProblem: GC kann bei tiefer Struktur selbst viel Speicher ben\u00f6tigen\n\n\nSweep: Linearer Scan \u00fcber alle Bl\u00f6cke im Heap\n\n\nNach dem Sweep die Markierung wieder resetten\n\n\n\n\n\n\nNun gibt es L\u00fccken im Speicher (Fragmentierung)\n\n\nFree list f\u00fchren mit freien Speicherbl\u00f6cken\n\n\nN\u00e4chstes mal: Objekte verschieben\n\n\n\n\n\n\n\n\nDetailaspekte\n\n\n\n\nProgramm darf eigentlich nicht laufen w\u00e4hrend dem Mark\n\n\nTechniken f\u00fcr Concurrent GC, um keine \u00c4nderungen w\u00e4hrend dem Mark zu verpassen\n\n\n\n\n\n\nAusf\u00fchrungszeitpunkt\n\n\nSp\u00e4testens, wenn der Heap voll sind\n\n\nOder prophylaktisch fr\u00fcher\n\n\n\n\n\n\nUnser GC l\u00e4uft sequentiell und exklusiv (nicht async), Programm ist unterbrochen\n\n\nRoot Set wird momentan vereinfacht auf das Main-Objekt\n\n\n\n\nWoche 2 - Vertiefung\n\n\nStack Root Set\n\n\n\n\nErkenne Referenzen auf dem Call Stack\n\n\nActivation Frame durchscanne\n\n\n\n\n\n\nLokale Variablen, Parameter (auch \nthis\n pointer)\n\n\nGC kann auch w\u00e4hrend einer Auswertung laufen, d.h. Pointer im Evaluation Stack beachten!\n\n\n\n\nFinalizer\n\n\n\n\n\u00dcblicherweise kommen Objekte nur einmal in die Finalizer-Liste, d.h. sie k\u00f6nnen sich h\u00f6chstens 1 Mal \"resurrecten\"\n\n\n\n\nWeak References\n\n\n\n\nNicht im Sinne von z.B. C++ Weak References, sondern f\u00fcr einen \"richtigen\" GC, d.h. Zyklen sind kein Problem", 
            "title": "Garbage Collection"
        }, 
        {
            "location": "/combau/garbage_collection/#garbage-collection", 
            "text": "", 
            "title": "Garbage Collection"
        }, 
        {
            "location": "/combau/garbage_collection/#memory-safety", 
            "text": "Bei uns werden Metadaten vom .NET-GC abger\u00e4umt  GC wird z.B. bei Webserver ben\u00f6tigt, wenn immer neue Objekte alloziert werden  Explizite Freigabe (mit  delete ) f\u00fchrt zu Dangling Pointers (zu fr\u00fche Freigabe) und Memory Leaks (zu sp\u00e4te / keine Freigabe)", 
            "title": "Memory Safety"
        }, 
        {
            "location": "/combau/garbage_collection/#garbage-collection_1", 
            "text": "Laufzeitsystem k\u00fcmmert sich um die Freigabe  Es gibt mehrere Techniken dazu  Garbage = Objekte, die  nicht mehr erreichbar sind  und daher nicht mehr gebraucht werden", 
            "title": "Garbage Collection"
        }, 
        {
            "location": "/combau/garbage_collection/#reference-counting", 
            "text": "Naive Variante von GC  z.B. von Objective C implementiert, bei C++ shared pointers  Idee: Eingehende Referenzen von einem Objekt z\u00e4hlen  Wenn die Zahl = 0 -  Ist Garbage  Bei Zyklischen Abh\u00e4ngigkeiten ist Garbage = Reference Count 0 nicht gegeben    Updates sind teuer  Die Reference Counts sind \"shared resources\", d.h. sie m\u00fcssen atomar geschrieben werden    Zyklische Strukturen werden nie zu Garbage, da sie sich immer gegenseitig (bzw. zyklisch) referenzieren  = Memory Leak  Viele Strukturen sind zyklisch  Wird z.B. bei C++ mit  weak_pointer  gel\u00f6st    Vorteil: Deallokation ist deterministisch bei letzter Dereferenzierung", 
            "title": "Reference Counting"
        }, 
        {
            "location": "/combau/garbage_collection/#garbage-collector", 
            "text": "Heap wird analysiert und Garbage freigegeben  Heap ist ein flacher Graph  L\u00e4uft nicht-deterministisch  Garbage sind Nodes im Graph, die vom \"Programm\" nicht mehr erreichbar sind  Laufendes Programm ist \"Root-Set\"  Root-Set besteht aus allen Referenzen im aktiven Frame auf dem Call Stack", 
            "title": "Garbage Collector"
        }, 
        {
            "location": "/combau/garbage_collection/#mark-sweep", 
            "text": "Markiere alle transitiven erreichbaren Objekte  Sweep: L\u00f6sche alle nicht markierte Objekte  Mit Tiefensuche alle Objekte von einem Root-Objekt aus traversieren  Problem: GC kann bei tiefer Struktur selbst viel Speicher ben\u00f6tigen  Sweep: Linearer Scan \u00fcber alle Bl\u00f6cke im Heap  Nach dem Sweep die Markierung wieder resetten    Nun gibt es L\u00fccken im Speicher (Fragmentierung)  Free list f\u00fchren mit freien Speicherbl\u00f6cken  N\u00e4chstes mal: Objekte verschieben", 
            "title": "Mark &amp; Sweep"
        }, 
        {
            "location": "/combau/garbage_collection/#detailaspekte", 
            "text": "Programm darf eigentlich nicht laufen w\u00e4hrend dem Mark  Techniken f\u00fcr Concurrent GC, um keine \u00c4nderungen w\u00e4hrend dem Mark zu verpassen    Ausf\u00fchrungszeitpunkt  Sp\u00e4testens, wenn der Heap voll sind  Oder prophylaktisch fr\u00fcher    Unser GC l\u00e4uft sequentiell und exklusiv (nicht async), Programm ist unterbrochen  Root Set wird momentan vereinfacht auf das Main-Objekt", 
            "title": "Detailaspekte"
        }, 
        {
            "location": "/combau/garbage_collection/#woche-2-vertiefung", 
            "text": "", 
            "title": "Woche 2 - Vertiefung"
        }, 
        {
            "location": "/combau/garbage_collection/#stack-root-set", 
            "text": "Erkenne Referenzen auf dem Call Stack  Activation Frame durchscanne    Lokale Variablen, Parameter (auch  this  pointer)  GC kann auch w\u00e4hrend einer Auswertung laufen, d.h. Pointer im Evaluation Stack beachten!", 
            "title": "Stack Root Set"
        }, 
        {
            "location": "/combau/garbage_collection/#finalizer", 
            "text": "\u00dcblicherweise kommen Objekte nur einmal in die Finalizer-Liste, d.h. sie k\u00f6nnen sich h\u00f6chstens 1 Mal \"resurrecten\"", 
            "title": "Finalizer"
        }, 
        {
            "location": "/combau/garbage_collection/#weak-references", 
            "text": "Nicht im Sinne von z.B. C++ Weak References, sondern f\u00fcr einen \"richtigen\" GC, d.h. Zyklen sind kein Problem", 
            "title": "Weak References"
        }, 
        {
            "location": "/combau/jit/", 
            "text": "Just-In-Time Compiler\n\n\n\n\nAusf\u00fchrung direkt auf Hardware (Intel 64) statt auf .NET Runtime\n\n\nnur kritische Teile, die oft ausgef\u00fchrt werden\n\n\nProfiling: Analyse zur Laufzeit, wie viel Codeausschnitte ausgef\u00fchrt werde, um \"Hot Spots\" zu finden\n\n\nAuf ebene Branches analysieren / z\u00e4hlen\n\n\n\n\n\n\n\n\nIntel 64 Architektur\n\n\n\n\nBenutzt Register (statt Stack)\n\n\n8[RCX]\n: Lies von Adresse \nRCX + 8\n (Von Memory in Register laden)\n\n\nSigned und Unsigned Integer Addition / Subtraktion sind die gleichen (wegen 2er Komplement)\n\n\nDivision und Modulo mit \nIDIV\n\n\nBei jeder Division wird von \nRAX\n als Dividend gelesen\n\n\nRDX\n muss 0 sein\n\n\nDas Argument ist der Divisor\n\n\nRAX = RAX / Argument\n\n\nRDX = RAX \n Argument\n\n\n\n\n\n\n\n\nCode Generation\n\n\n\n\nTemplate-based: Codemuster aus IL erkennen (z.B. f\u00fcr jede Instruktion) und daraus Intel64-Code generieren\n\n\n\n\nRegister Allocation\n\n\n\n\nIn den \"Templates\" muss man wissen, in welchen Register was liegt und in welche was geschrieben werden soll\n\n\nDazu ein Register-Stack f\u00fchren, der wie Evaluation-Stack verl\u00e4uft\n\n\nStatt beim Eval-Stack die Werte selbst, wird im Register-Stack geschrieben, in welchen Registern die Werte liegen\n\n\nBei Division braucht es das \nRDX\n-Register, und im \nRAX\n muss der Dividend stehen\n\n\nRAX\n und \nRDX\n tempor\u00e4r in freie Register kopieren\n\n\n\n\n\n\n\n\nBranches\n\n\n\n\nBei conditional jumps immer zuerst \nCMP\n, dann \nJE\n, \nJNE\n usw.", 
            "title": "Just-in-Time Compiler"
        }, 
        {
            "location": "/combau/jit/#just-in-time-compiler", 
            "text": "Ausf\u00fchrung direkt auf Hardware (Intel 64) statt auf .NET Runtime  nur kritische Teile, die oft ausgef\u00fchrt werden  Profiling: Analyse zur Laufzeit, wie viel Codeausschnitte ausgef\u00fchrt werde, um \"Hot Spots\" zu finden  Auf ebene Branches analysieren / z\u00e4hlen", 
            "title": "Just-In-Time Compiler"
        }, 
        {
            "location": "/combau/jit/#intel-64-architektur", 
            "text": "Benutzt Register (statt Stack)  8[RCX] : Lies von Adresse  RCX + 8  (Von Memory in Register laden)  Signed und Unsigned Integer Addition / Subtraktion sind die gleichen (wegen 2er Komplement)  Division und Modulo mit  IDIV  Bei jeder Division wird von  RAX  als Dividend gelesen  RDX  muss 0 sein  Das Argument ist der Divisor  RAX = RAX / Argument  RDX = RAX   Argument", 
            "title": "Intel 64 Architektur"
        }, 
        {
            "location": "/combau/jit/#code-generation", 
            "text": "Template-based: Codemuster aus IL erkennen (z.B. f\u00fcr jede Instruktion) und daraus Intel64-Code generieren", 
            "title": "Code Generation"
        }, 
        {
            "location": "/combau/jit/#register-allocation", 
            "text": "In den \"Templates\" muss man wissen, in welchen Register was liegt und in welche was geschrieben werden soll  Dazu ein Register-Stack f\u00fchren, der wie Evaluation-Stack verl\u00e4uft  Statt beim Eval-Stack die Werte selbst, wird im Register-Stack geschrieben, in welchen Registern die Werte liegen  Bei Division braucht es das  RDX -Register, und im  RAX  muss der Dividend stehen  RAX  und  RDX  tempor\u00e4r in freie Register kopieren", 
            "title": "Register Allocation"
        }, 
        {
            "location": "/combau/jit/#branches", 
            "text": "Bei conditional jumps immer zuerst  CMP , dann  JE ,  JNE  usw.", 
            "title": "Branches"
        }, 
        {
            "location": "/dl/", 
            "text": "Deep Learning", 
            "title": "Index"
        }, 
        {
            "location": "/dl/#deep-learning", 
            "text": "", 
            "title": "Deep Learning"
        }, 
        {
            "location": "/dl/linear_algebra/", 
            "text": "Linear Algebra\n\n\n\n\nIndices in Matrix: First index is row (\ni\n: row, \nj\n: column)\n\n\nA 3D (or higher-dimensional) array is a \ntensor\n\n\nIn DL, we add scalars to matrices (not in linearl algebra): \nD_{i,j} = a \\cdot B_{i,j} + c\n\n\n\n\n\n\nMatrix Multiplication\n\n\n\n\nDimensions must be (q,p) = (q,k)(k,p)\n\n\nk\n-sized vectors are multiplied together\n\n\n\n\n\n\nHadamard Prodcut\n: Element-wise product, dimensions must be the same\n\n\nMatrix multiplication is associative and distributive, but \nnot commutative\n\n\n\n\nAB \\neq BA\n\n\n\n\n\n\n\n\n\n\nInverse Matrix\n\n\n\n\nMatrix which when multiplied with A will result in the Identity Matrix\n\n\nUsed for solving equations\n\n\n\n\nAx = b \\Rightarrow x = A^{-1}b\n\n\n\n\nNumerically not ideal\n\n\n\n\n\n\nEquation system could also have no or infinite solutions\n\n\nNo \"multipled solutions\", because an infinite number of solutions can be built with two of them\n\n\n\n\n\n\nFor \nA^{-1}\n to exist, we need \nm = n\n and all columns must be \nlinearly independent\n\n\nmeaning no vector can be created by scaling two others\n\n\n\n\n\n\n\n\nNorms\n\n\n\n\nMeasure to measure the length of a vector\n\n\nMost \"famous\": Euclidian norm (\"pythagoras\")\n\n\nThe \nsquared\n euclidian norm can be calculates as \nx^Tx\n\n\n\n\n\n\nL^1\n-norm: Add up every absolute value of the vector\n\n\nBetter for values closer to zero\n\n\n\n\n\n\n\n\nL^0\n-norm: Count the number of non-zero entries\n\n\nnot a mathematical norm\n, properties of a norm don't hold\n\n\n\n\n\n\n\n\nL^\\infty\n is just the max\n\n\nFrobenius norm: Square every entry of a Matrix and square the result\n\n\n\n\nSpecial Matrices\n\n\n\n\nDiagonal Matrix: Everything 0 except diagonal\n\n\ndiag(v)\n: \nv\n is the vector formed by the diagonal\n\n\ndiag(v)^-1\n = `diag([1/v1, ... 1/vn])\n\n\nSymmetric matrix: \nA = A^{-1}\n\n\n\n\northogonal matrix: rows and columns are mutually orthonormal\n\n\ntwo vectors orthonomal =\n dot product = 0\n\n\n\n\n\n\n\n\nEigendecomposition\n\n\n\n\n\n\nAv = \\lambda v\n\n\n\n\nWe need to find Eigenvector \nv\n and Eigenvalue (\\lambda)\n\n\nWe usually scale the Eigenvector to have length 1 (euclidian norm)\n\n\n\n\nA = V \\text{diag}(\\lambda)V^{-1}", 
            "title": "Linear Algebra"
        }, 
        {
            "location": "/dl/linear_algebra/#linear-algebra", 
            "text": "Indices in Matrix: First index is row ( i : row,  j : column)  A 3D (or higher-dimensional) array is a  tensor  In DL, we add scalars to matrices (not in linearl algebra):  D_{i,j} = a \\cdot B_{i,j} + c", 
            "title": "Linear Algebra"
        }, 
        {
            "location": "/dl/linear_algebra/#matrix-multiplication", 
            "text": "Dimensions must be (q,p) = (q,k)(k,p)  k -sized vectors are multiplied together    Hadamard Prodcut : Element-wise product, dimensions must be the same  Matrix multiplication is associative and distributive, but  not commutative   AB \\neq BA", 
            "title": "Matrix Multiplication"
        }, 
        {
            "location": "/dl/linear_algebra/#inverse-matrix", 
            "text": "Matrix which when multiplied with A will result in the Identity Matrix  Used for solving equations   Ax = b \\Rightarrow x = A^{-1}b   Numerically not ideal    Equation system could also have no or infinite solutions  No \"multipled solutions\", because an infinite number of solutions can be built with two of them    For  A^{-1}  to exist, we need  m = n  and all columns must be  linearly independent  meaning no vector can be created by scaling two others", 
            "title": "Inverse Matrix"
        }, 
        {
            "location": "/dl/linear_algebra/#norms", 
            "text": "Measure to measure the length of a vector  Most \"famous\": Euclidian norm (\"pythagoras\")  The  squared  euclidian norm can be calculates as  x^Tx    L^1 -norm: Add up every absolute value of the vector  Better for values closer to zero     L^0 -norm: Count the number of non-zero entries  not a mathematical norm , properties of a norm don't hold     L^\\infty  is just the max  Frobenius norm: Square every entry of a Matrix and square the result", 
            "title": "Norms"
        }, 
        {
            "location": "/dl/linear_algebra/#special-matrices", 
            "text": "Diagonal Matrix: Everything 0 except diagonal  diag(v) :  v  is the vector formed by the diagonal  diag(v)^-1  = `diag([1/v1, ... 1/vn])  Symmetric matrix:  A = A^{-1}   orthogonal matrix: rows and columns are mutually orthonormal  two vectors orthonomal =  dot product = 0", 
            "title": "Special Matrices"
        }, 
        {
            "location": "/dl/linear_algebra/#eigendecomposition", 
            "text": "Av = \\lambda v   We need to find Eigenvector  v  and Eigenvalue (\\lambda)  We usually scale the Eigenvector to have length 1 (euclidian norm)   A = V \\text{diag}(\\lambda)V^{-1}", 
            "title": "Eigendecomposition"
        }, 
        {
            "location": "/dl/numerical_computation/", 
            "text": "Numerical Computation\n\n\n\n\nMost of this is handled by frameworks\n\n\n\n\nOverflow and Underflow\n\n\n\n\nUnderflow: So small that they're basically 0\n\n\n\n\n\\log x\n when x is zero: \n-\\infty\n\n\n\n\n\n\n\n\nsoftmax takes a vector, the sum will be 1, and every number will be positive -\n probability distribution\n\n\nsigmoid is softmax with 2 dimensions, where \nx = x_1 - x_2\n\n\n\n\nif the numbers in the vector are very large or very small (negative), there's an underflow / overflow problem\n\n\nsolution: subtract the max of the vector from every entry, and use the softmax on that\n\n\n\n\n\n\noften, we optimize for the log of probabilities -\n \n\\log \\text{softmax}\n\n\n\n\nuseful, because log and exp cancel each other out\n\n\ncalled \"logsoftmax\"\n\n\n\n\n\n\n\n\nPoor Conditioning\n\n\n\n\nProblem: Small change in input produces very large change in output\n\n\n\n\nGradient-Based Optimization\n\n\n\n\n\n\narg min f(x)\n: the argument \nx\n that produces the minimum of \nf(x)\n\n\n\n\nCalled the \"minimizer\"\n\n\nf(arg min f(x)) = min\n\n\n\n\n\n\nIdea: if the slope is negative, walk forwards, if it's positive, walk backwards: \"gradient descent\"\n\n\nGives us a minimum\n\n\nGradient = derivative in multiple dimensions\n\n\nIf the gradient is 0, we're either at a minimum, a maximum or a \nsaddle point\n\n\nsaddle points are common in higher dimensions\n\n\n\n\n\n\nthe goal is finding a global minimum, but we don't know if we've found it with gradient descent, except if the function is \"convex\", e.g. a quadratic function with one minimum\n\n\nThere's a derivative for every dimension\n\n\nThe gradient is a vector with all the partial derivatives for every dimension\n\n\n\n\nGradient descent for vectors\n\n\n\n\nGradient is vector that points to the steepest slope\n\n\nWe want to go in the reverse opposite of that vector to find the minimum\n\n\nanalogy: Go down a mountain by taking the steepest step each time, you'd find the valley\n\n\nminimizing: cos should be -1 -\n 180\u00b0\n\n\nThe opposite direction of \nu\n (the steepest direction)\n\n\n\n\n\n\n\n\nJacobian and Hessian Matrices\n\n\n\n\n\n\nf(x)\n is now mapping from n-dimensional to m-dimensional vector\n\n\ne.g. common between two layers in a neural network\n\n\n\n\n\n\nThe Jacobian matrix \nJ\n captures the derivate of every input entry w.r.t. to every output entry, so it's a n by m matrix\n\n\nderivates say how the change of one value affects the other\n\n\n\n\n\n\nDerivatives of derivatives can be in different directions, so there are a lot of combinations\n\n\nSecond derivative = curvature\n\n\nThe curvature of a plane is 0\n\n\nThis makes gradient descent \"easy\", just follow the derivative\n\n\n\n\n\n\nAll the combinations of curvature are captured in the Hessian matrix \nH\n\n\n\n\nThe optimal \n\\epsilon\n could be calculated with the Hessian matrix, but that's too hard to calculate (and store), so not practical\n\n\nWe can determine if we're at a minimum, maximum with the second derivative\n\n\nIf the derivate is 0, it could be a saddle point, but the test is inconclusive\n\n\nThe same concept works in higher dimensions with eigenvalues\n\n\nIf not all eigenvalues are either positive or negative, we're at a saddle point\n\n\nAlmost a chance of 1\n\n\n\n\n\n\nThe condition number tells us how much the space is \"warped\"\n\n\nif the condition number is high, gradient descent is harder (slower)", 
            "title": "Numerical Computation"
        }, 
        {
            "location": "/dl/numerical_computation/#numerical-computation", 
            "text": "Most of this is handled by frameworks", 
            "title": "Numerical Computation"
        }, 
        {
            "location": "/dl/numerical_computation/#overflow-and-underflow", 
            "text": "Underflow: So small that they're basically 0   \\log x  when x is zero:  -\\infty     softmax takes a vector, the sum will be 1, and every number will be positive -  probability distribution  sigmoid is softmax with 2 dimensions, where  x = x_1 - x_2   if the numbers in the vector are very large or very small (negative), there's an underflow / overflow problem  solution: subtract the max of the vector from every entry, and use the softmax on that    often, we optimize for the log of probabilities -   \\log \\text{softmax}   useful, because log and exp cancel each other out  called \"logsoftmax\"", 
            "title": "Overflow and Underflow"
        }, 
        {
            "location": "/dl/numerical_computation/#poor-conditioning", 
            "text": "Problem: Small change in input produces very large change in output", 
            "title": "Poor Conditioning"
        }, 
        {
            "location": "/dl/numerical_computation/#gradient-based-optimization", 
            "text": "arg min f(x) : the argument  x  that produces the minimum of  f(x)   Called the \"minimizer\"  f(arg min f(x)) = min    Idea: if the slope is negative, walk forwards, if it's positive, walk backwards: \"gradient descent\"  Gives us a minimum  Gradient = derivative in multiple dimensions  If the gradient is 0, we're either at a minimum, a maximum or a  saddle point  saddle points are common in higher dimensions    the goal is finding a global minimum, but we don't know if we've found it with gradient descent, except if the function is \"convex\", e.g. a quadratic function with one minimum  There's a derivative for every dimension  The gradient is a vector with all the partial derivatives for every dimension", 
            "title": "Gradient-Based Optimization"
        }, 
        {
            "location": "/dl/numerical_computation/#gradient-descent-for-vectors", 
            "text": "Gradient is vector that points to the steepest slope  We want to go in the reverse opposite of that vector to find the minimum  analogy: Go down a mountain by taking the steepest step each time, you'd find the valley  minimizing: cos should be -1 -  180\u00b0  The opposite direction of  u  (the steepest direction)", 
            "title": "Gradient descent for vectors"
        }, 
        {
            "location": "/dl/numerical_computation/#jacobian-and-hessian-matrices", 
            "text": "f(x)  is now mapping from n-dimensional to m-dimensional vector  e.g. common between two layers in a neural network    The Jacobian matrix  J  captures the derivate of every input entry w.r.t. to every output entry, so it's a n by m matrix  derivates say how the change of one value affects the other    Derivatives of derivatives can be in different directions, so there are a lot of combinations  Second derivative = curvature  The curvature of a plane is 0  This makes gradient descent \"easy\", just follow the derivative    All the combinations of curvature are captured in the Hessian matrix  H   The optimal  \\epsilon  could be calculated with the Hessian matrix, but that's too hard to calculate (and store), so not practical  We can determine if we're at a minimum, maximum with the second derivative  If the derivate is 0, it could be a saddle point, but the test is inconclusive  The same concept works in higher dimensions with eigenvalues  If not all eigenvalues are either positive or negative, we're at a saddle point  Almost a chance of 1    The condition number tells us how much the space is \"warped\"  if the condition number is high, gradient descent is harder (slower)", 
            "title": "Jacobian and Hessian Matrices"
        }, 
        {
            "location": "/dl/ml_basics/", 
            "text": "Machine Learning Basics\n\n\n\n\n\"Generalization\": Perform well on data it hasn't seen before\n\n\nLinear regression measures the error on the training data, not on the test data\n\n\nOnly works if training and test data sets have the same distribution\n\n\n\n\n\n\nThe \"i.i.d. assumptions\"\n\n\nAssume that all examples are independent, and training and test set are identically distributed\n\n\nUse distribution of one sample to generate all test and training samples\n\n\nOptimizing for the training data will therefore also optimize for the test data\n\n\n\n\n\n\nOverfitting: Reach a low training error, but the test error is much larger\n\n\ni.e. no generalization, only \"memorized\" the training data\n\n\nGiving it too much capacity\n\n\n\n\n\n\nCapacity: Flexibility the system has\n\n\ne.g. for linear regression, increase capacity by allowing higher-order polynomials\n\n\n\n\n\n\n\n\nCheck for systems: If you can't get your system to overfit (by giving it lots of capacity), it doesn't learn properly\n\n\n\n\n\n\nEven with a perfect model, with a reasonably complex system, there's always an error\n\n\n\n\ne.g. digital communication: noise makes it impossible to always decide correctly (between 1 and 0)\n\n\n\n\n\n\n\n\n\"No Free Lunch\" theorem: No machine learning algorithm is universally better than any other\n\n\n\n\nBut assumes data of all possible distributions\n\n\nIn ML, we always concentrate on a limited range of data\n\n\ni.e. there's no \"general\" good ML algorithm\n\n\n\n\n\n\n\n\nRegularization\n\n\n\n\n\n\n\\lambda w^T w\n: All elements squared and summed up\n\n\ni.e. small weights are preferable for low cost\n\n\n\n\n\n\nIf we pick \n\\lambda\n to be large, weights will almost be zero to achieve minimal cost (underfitting)\n\n\nAlso called a \"penalty term\"\n\n\nGoal ist to minimize the generalization error but not the training error\n\n\n\n\nHyperparameters\n\n\n\n\n\n\n\\lambda\n is a \"hyperparameter\"\n\n\nparameters that are not learned by the scheme\n\n\nto train these parameters, we use part of the training data as \"validation data\" to \"tune\" the algorithm\n\n\n\n\n\n\nAfter we've used a test set once, it is \"tainted\" and should theoretically not be used anymore\n\n\nhard in practice to have enough data\n\n\n\n\n\n\n\n\nEstimators, Bias, Variance\n\n\n\n\nEstimator: \"Sch\u00e4tzer\"\n\n\nBias: Difference between Error of \"guess\" and real data\n\n\nEstimator is unbiased: It is on average right (\"Erwartungstreu\")\n\n\nVariance of Estimator\n\n\n\"SE\": Standard Error, a.k.a \n\\sqrt{var(x)}\n\n\n\n\n\n\n\n\nThe variance of a sample is \n\\frac{\\sigma}{\\sqrt m}\n\n\n\n\ni.e. lots of data reduces the variance of the estimator\n\n\n\n\n\n\nConsistency: In the limit, the estimator \"guesses the right value\"\n\n\nVariance goes towards zero\n\n\n\n\n\n\n\n\nMaximum Likelihood Estimation\n\n\n\n\n\n\n\\theta\n are free variables\n\n\nWeights of the network in a neural network\n\n\n\n\n\n\nFind \n\\theta\n such that the likelihood that the model is producing the \"correct\" values is maximized\n\n\nUsually, the log of the likelihood is maximized\n\n\nKL divergence: Measures how similar to distributions are\n\n\nGoal: minimize KL divergence\n\n\n\n\n\n\n\n\n\n\nTodo\n\n\nChapters 5.7 and 5.8 (supervised vs unsupervised learning) \n\n\n\n\nStochastic Gradient Descent\n\n\n\n\nGradient Descent with a limited sample\n\n\nNegative log-likelihood is the cost function\n\n\nMinimizing this cost = maximizing likelihood\n\n\n\n\n\n\nGradients over all of millions data points would take forever\n\n\nUse a select few of the data as an \nestimate\n of the gradient\n\n\nThis subset is called a \"minibatch\"\n\n\nHas to be chosen truly randomly from the whole data set\n\n\n\n\n\n\nlearning rate: step size for gradient descent\n\n\n\n\nBuilding a ML algorithm\n\n\n\n\nOnly gets useful once you have a lot of data", 
            "title": "Machine Learning Basics"
        }, 
        {
            "location": "/dl/ml_basics/#machine-learning-basics", 
            "text": "\"Generalization\": Perform well on data it hasn't seen before  Linear regression measures the error on the training data, not on the test data  Only works if training and test data sets have the same distribution    The \"i.i.d. assumptions\"  Assume that all examples are independent, and training and test set are identically distributed  Use distribution of one sample to generate all test and training samples  Optimizing for the training data will therefore also optimize for the test data    Overfitting: Reach a low training error, but the test error is much larger  i.e. no generalization, only \"memorized\" the training data  Giving it too much capacity    Capacity: Flexibility the system has  e.g. for linear regression, increase capacity by allowing higher-order polynomials     Check for systems: If you can't get your system to overfit (by giving it lots of capacity), it doesn't learn properly    Even with a perfect model, with a reasonably complex system, there's always an error   e.g. digital communication: noise makes it impossible to always decide correctly (between 1 and 0)     \"No Free Lunch\" theorem: No machine learning algorithm is universally better than any other   But assumes data of all possible distributions  In ML, we always concentrate on a limited range of data  i.e. there's no \"general\" good ML algorithm", 
            "title": "Machine Learning Basics"
        }, 
        {
            "location": "/dl/ml_basics/#regularization", 
            "text": "\\lambda w^T w : All elements squared and summed up  i.e. small weights are preferable for low cost    If we pick  \\lambda  to be large, weights will almost be zero to achieve minimal cost (underfitting)  Also called a \"penalty term\"  Goal ist to minimize the generalization error but not the training error", 
            "title": "Regularization"
        }, 
        {
            "location": "/dl/ml_basics/#hyperparameters", 
            "text": "\\lambda  is a \"hyperparameter\"  parameters that are not learned by the scheme  to train these parameters, we use part of the training data as \"validation data\" to \"tune\" the algorithm    After we've used a test set once, it is \"tainted\" and should theoretically not be used anymore  hard in practice to have enough data", 
            "title": "Hyperparameters"
        }, 
        {
            "location": "/dl/ml_basics/#estimators-bias-variance", 
            "text": "Estimator: \"Sch\u00e4tzer\"  Bias: Difference between Error of \"guess\" and real data  Estimator is unbiased: It is on average right (\"Erwartungstreu\")  Variance of Estimator  \"SE\": Standard Error, a.k.a  \\sqrt{var(x)}     The variance of a sample is  \\frac{\\sigma}{\\sqrt m}   i.e. lots of data reduces the variance of the estimator    Consistency: In the limit, the estimator \"guesses the right value\"  Variance goes towards zero", 
            "title": "Estimators, Bias, Variance"
        }, 
        {
            "location": "/dl/ml_basics/#maximum-likelihood-estimation", 
            "text": "\\theta  are free variables  Weights of the network in a neural network    Find  \\theta  such that the likelihood that the model is producing the \"correct\" values is maximized  Usually, the log of the likelihood is maximized  KL divergence: Measures how similar to distributions are  Goal: minimize KL divergence      Todo  Chapters 5.7 and 5.8 (supervised vs unsupervised learning)", 
            "title": "Maximum Likelihood Estimation"
        }, 
        {
            "location": "/dl/ml_basics/#stochastic-gradient-descent", 
            "text": "Gradient Descent with a limited sample  Negative log-likelihood is the cost function  Minimizing this cost = maximizing likelihood    Gradients over all of millions data points would take forever  Use a select few of the data as an  estimate  of the gradient  This subset is called a \"minibatch\"  Has to be chosen truly randomly from the whole data set    learning rate: step size for gradient descent", 
            "title": "Stochastic Gradient Descent"
        }, 
        {
            "location": "/dl/ml_basics/#building-a-ml-algorithm", 
            "text": "Only gets useful once you have a lot of data", 
            "title": "Building a ML algorithm"
        }, 
        {
            "location": "/dl/deep_feed-forward_networks/", 
            "text": "Deep Feedforward Network\n\n\nBasics\n\n\n\n\nIn supervised learning, we know the desired output for a given input\n\n\n\n\n\\theta\n represents the parameters of the network, a.k.a the weights and biases\n\n\nthe middle layers are \"hidden layers\", because we don't know what good values for them are\n\n\n\n\nXOR Example\n\n\n\n\nAnswer with linear regression is always \n, since it has the LSE\n\n\n\n\nGradient-Based Learning\n\n\n\n\nInitialize weights with small random values\n\n\nOtherwise the output is just 0\n\n\nAnd to break symmetry between neuros, otherwise they would do similar / same things\n\n\n\n\n\n\nSigmoid used to be popular, but now ReLU is mostly used (\nmax(0, z)\n)\n\n\nGood Architecture is not well-defined\n\n\nHow many units, layers, etc.?\n\n\napproach: Use someone else's architecture that already works\n\n\nThere are rarely completely new problems\n\n\n\n\n\n\n\n\nBack Propagation\n\n\n\n\nBasically calculates the gradient of the cost functions with respect to the weights and biases\n\n\nThe gradient is calculated \nanalytically\n, not computationally\n\n\n\n\nChain Rule\n\n\n\n\nFF-Network is like a nested function (with each layer)\n\n\nbackprop is a dynamic algorithm that calculates the chain rule efficiently\n\n\nJacobian-matrix is diagonal if the function is element-wise\n\n\nReLU and sigmoid are", 
            "title": "Deep Feedforward Networks"
        }, 
        {
            "location": "/dl/deep_feed-forward_networks/#deep-feedforward-network", 
            "text": "", 
            "title": "Deep Feedforward Network"
        }, 
        {
            "location": "/dl/deep_feed-forward_networks/#basics", 
            "text": "In supervised learning, we know the desired output for a given input   \\theta  represents the parameters of the network, a.k.a the weights and biases  the middle layers are \"hidden layers\", because we don't know what good values for them are", 
            "title": "Basics"
        }, 
        {
            "location": "/dl/deep_feed-forward_networks/#xor-example", 
            "text": "Answer with linear regression is always  , since it has the LSE", 
            "title": "XOR Example"
        }, 
        {
            "location": "/dl/deep_feed-forward_networks/#gradient-based-learning", 
            "text": "Initialize weights with small random values  Otherwise the output is just 0  And to break symmetry between neuros, otherwise they would do similar / same things    Sigmoid used to be popular, but now ReLU is mostly used ( max(0, z) )  Good Architecture is not well-defined  How many units, layers, etc.?  approach: Use someone else's architecture that already works  There are rarely completely new problems", 
            "title": "Gradient-Based Learning"
        }, 
        {
            "location": "/dl/deep_feed-forward_networks/#back-propagation", 
            "text": "Basically calculates the gradient of the cost functions with respect to the weights and biases  The gradient is calculated  analytically , not computationally", 
            "title": "Back Propagation"
        }, 
        {
            "location": "/dl/deep_feed-forward_networks/#chain-rule", 
            "text": "FF-Network is like a nested function (with each layer)  backprop is a dynamic algorithm that calculates the chain rule efficiently  Jacobian-matrix is diagonal if the function is element-wise  ReLU and sigmoid are", 
            "title": "Chain Rule"
        }, 
        {
            "location": "/dl/regularization/", 
            "text": "Regularization for Deep Learning\n\n\n\n\nGoal: Make the algorithm \"generalize\", e.g. that it will perform well on data it has never been trained with\n\n\nWe don't want to memorize the training data\n\n\n\n\nParameter Regularization\n\n\n\n\nTake e.g. the L2-Norm\n\n\nMultiply it with a hyperparameter \n\\alpha\n and add it to the cost function\n\n\nGoal: Weights should be small (weight decay)\n\n\nwith \n(1 - \\epsilon \\alpha)w\n, weights want to go towards zero\n\n\n\n\nIntuition: Small curvatures get pulled to zero, big curvatures don't get affected by the regularization\n\n\n\n\n\n\nL1-Regularization is a \"soft threshold\" that makes a lot of weights go to zero\n\n\n\n\nFewer values to calculate\n\n\n\n\n\n\n\n\nDataset Augmentation\n\n\n\n\nCreate artificial training data\n\n\ne.g. for picture classification: Just turn the image slightly, or zoom in / out, darken / brighten, etc.\n\n\nThe label stays the same, but we can multiply the training set\n\n\ni.e. a transformation that changes the input x, but not the output y\n\n\ninject noise to make the dataset more non-deterministic\n\n\nWe could also apply noise to the weights. Bayes philosophy that weights are just random variables with DFs, noise is a way to simulate that", 
            "title": "Regularization"
        }, 
        {
            "location": "/dl/regularization/#regularization-for-deep-learning", 
            "text": "Goal: Make the algorithm \"generalize\", e.g. that it will perform well on data it has never been trained with  We don't want to memorize the training data", 
            "title": "Regularization for Deep Learning"
        }, 
        {
            "location": "/dl/regularization/#parameter-regularization", 
            "text": "Take e.g. the L2-Norm  Multiply it with a hyperparameter  \\alpha  and add it to the cost function  Goal: Weights should be small (weight decay)  with  (1 - \\epsilon \\alpha)w , weights want to go towards zero   Intuition: Small curvatures get pulled to zero, big curvatures don't get affected by the regularization    L1-Regularization is a \"soft threshold\" that makes a lot of weights go to zero   Fewer values to calculate", 
            "title": "Parameter Regularization"
        }, 
        {
            "location": "/dl/regularization/#dataset-augmentation", 
            "text": "Create artificial training data  e.g. for picture classification: Just turn the image slightly, or zoom in / out, darken / brighten, etc.  The label stays the same, but we can multiply the training set  i.e. a transformation that changes the input x, but not the output y  inject noise to make the dataset more non-deterministic  We could also apply noise to the weights. Bayes philosophy that weights are just random variables with DFs, noise is a way to simulate that", 
            "title": "Dataset Augmentation"
        }
    ]
}